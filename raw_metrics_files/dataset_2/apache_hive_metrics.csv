SmellMetrics,Seg, 4 jun 2018 18:34:51 BRT
Method,CALL,CALLED,IMP,LOC,NBD,NP,STAT,v(G)
"null.checkType(String)",1,1,n/a,2,0,1,1,1
"null.compare(String,String)",1,0,n/a,4,0,2,1,1
"null.defaultValueString(ConfVars)",0,1,n/a,2,0,1,1,1
"null.getAggregator(Configuration)",1,0,n/a,3,0,1,1,1
"null.getPublisher(Configuration)",1,0,n/a,3,0,1,1,1
"null.inRange(String,Object,Object)",1,1,n/a,5,0,3,2,2
"null.initialValue()",1,0,n/a,4,0,0,1,1
"null.run()",7,1,n/a,12,2,0,5,3
"org.apache.hadoop.hive.ant.GenHiveTemplate.appendElement(Element,String,String)",5,4,n/a,10,1,3,7,2
"org.apache.hadoop.hive.ant.GenHiveTemplate.execute()",2,0,n/a,8,1,0,3,2
"org.apache.hadoop.hive.ant.GenHiveTemplate.generate()",11,2,n/a,14,3,0,9,5
"org.apache.hadoop.hive.ant.GenHiveTemplate.generateTemplate()",29,1,n/a,44,2,0,20,3
"org.apache.hadoop.hive.ant.GenHiveTemplate.getTemplateFile()",0,0,n/a,3,0,0,1,1
"org.apache.hadoop.hive.ant.GenHiveTemplate.main(String[])",2,0,n/a,4,0,1,2,1
"org.apache.hadoop.hive.ant.GenHiveTemplate.normalize(String)",13,1,n/a,16,1,1,12,4
"org.apache.hadoop.hive.ant.GenHiveTemplate.setTemplateFile(String)",0,0,n/a,3,0,1,1,1
"org.apache.hadoop.hive.ant.GenHiveTemplate.writeToFile(File,Document)",7,1,n/a,8,0,2,6,1
"org.apache.hadoop.hive.common.CompressionUtils.tar(String,String[],String)",16,0,n/a,33,3,3,18,2
"org.apache.hadoop.hive.common.FileUtils.AcceptAllPathFilter.accept(Path)",0,0,n/a,4,0,1,1,1
"org.apache.hadoop.hive.common.FileUtils.FileUtils()",0,0,n/a,3,0,0,0,1
"org.apache.hadoop.hive.common.FileUtils.checkDeletePermission(Path,Configuration,String)",15,0,n/a,51,1,3,16,5
"org.apache.hadoop.hive.common.FileUtils.checkFileAccessWithImpersonation(FileSystem,FileStatus,FsAction,String)",18,2,n/a,6,2,4,10,3
"org.apache.hadoop.hive.common.FileUtils.copy(FileSystem,Path,FileSystem,Path,boolean,boolean,HiveConf)",6,0,n/a,21,2,7,9,4
"org.apache.hadoop.hive.common.FileUtils.equalsFileSystem(FileSystem,FileSystem)",3,0,n/a,14,0,2,1,1
"org.apache.hadoop.hive.common.FileUtils.escapePathName(String)",1,3,n/a,3,0,1,1,1
"org.apache.hadoop.hive.common.FileUtils.escapePathName(String,String)",10,3,n/a,31,2,2,14,6
"org.apache.hadoop.hive.common.FileUtils.getPathOrParentThatExists(FileSystem,Path)",3,1,n/a,17,1,2,4,2
"org.apache.hadoop.hive.common.FileUtils.isActionPermittedForFileHierarchy(FileSystem,FileStatus,String,FsAction)",6,1,n/a,39,2,4,14,6
"org.apache.hadoop.hive.common.FileUtils.isLocalFile(HiveConf,String)",5,0,n/a,18,1,2,6,3
"org.apache.hadoop.hive.common.FileUtils.isOwnerOfFileHierarchy(FileSystem,FileStatus,String)",6,1,n/a,19,2,3,9,5
"org.apache.hadoop.hive.common.FileUtils.listStatusRecursively(FileSystem,FileStatus,List<FileStatus>)",9,2,n/a,5,3,3,6,4
"org.apache.hadoop.hive.common.FileUtils.makeDefaultListBucketingDirName(List<String>,String)",6,0,n/a,21,2,2,11,3
"org.apache.hadoop.hive.common.FileUtils.makeListBucketingDirName(List<String>,List<String>)",12,0,n/a,18,2,2,10,3
"org.apache.hadoop.hive.common.FileUtils.makePartName(List<String>,List<String>)",1,0,n/a,3,0,2,1,1
"org.apache.hadoop.hive.common.FileUtils.makePartName(List<String>,List<String>,String)",12,1,n/a,21,2,3,10,3
"org.apache.hadoop.hive.common.FileUtils.makeQualified(Path,Configuration)",15,0,n/a,47,3,2,16,7
"org.apache.hadoop.hive.common.FileUtils.mkdir(FileSystem,Path,boolean,Configuration)",11,0,n/a,44,3,4,19,6
"org.apache.hadoop.hive.common.FileUtils.moveToTrash(FileSystem,Path,Configuration)",6,1,n/a,21,1,3,9,3
"org.apache.hadoop.hive.common.FileUtils.needsEscaping(char)",2,1,n/a,3,0,1,1,3
"org.apache.hadoop.hive.common.FileUtils.renameWithPerms(FileSystem,Path,Path,boolean,Configuration)",8,0,n/a,22,3,5,11,4
"org.apache.hadoop.hive.common.FileUtils.trashFilesUnderDir(FileSystem,Path,Configuration)",3,0,n/a,17,1,3,5,2
"org.apache.hadoop.hive.common.FileUtils.unescapePathName(String)",9,0,n/a,21,3,1,16,6
"org.apache.hadoop.hive.common.HiveInterruptCallback.interrupt()",n/a,1,0,n/a,n/a,0,n/a,n/a
"org.apache.hadoop.hive.common.HiveInterruptUtils.add(HiveInterruptCallback)",1,0,n/a,6,1,1,3,1
"org.apache.hadoop.hive.common.HiveInterruptUtils.checkInterrupted()",4,0,n/a,14,2,0,6,3
"org.apache.hadoop.hive.common.HiveInterruptUtils.interrupt()",2,0,n/a,10,2,0,3,2
"org.apache.hadoop.hive.common.HiveInterruptUtils.remove(HiveInterruptCallback)",1,0,n/a,6,1,1,3,1
"org.apache.hadoop.hive.common.HiveStatsUtils.getFileStatusRecurse(Path,int,FileSystem)",13,0,n/a,37,2,3,14,4
"org.apache.hadoop.hive.common.JavaUtils.JavaUtils()",0,0,n/a,3,0,0,0,1
"org.apache.hadoop.hive.common.JavaUtils.closeClassLoader(ClassLoader)",15,1,n/a,32,3,1,18,7
"org.apache.hadoop.hive.common.JavaUtils.closeClassLoadersTo(ClassLoader,ClassLoader)",6,0,n/a,13,2,2,7,5
"org.apache.hadoop.hive.common.JavaUtils.getClassLoader()",3,0,n/a,15,1,0,4,2
"org.apache.hadoop.hive.common.JavaUtils.isValidHierarchy(ClassLoader,ClassLoader)",1,1,n/a,9,1,2,5,6
"org.apache.hadoop.hive.common.LogUtils.LogInitializationException.LogInitializationException(String)",1,1,n/a,3,0,1,1,1
"org.apache.hadoop.hive.common.LogUtils.initHiveExecLog4j()",1,0,n/a,10,0,0,1,1
"org.apache.hadoop.hive.common.LogUtils.initHiveLog4j()",1,0,n/a,10,0,0,1,1
"org.apache.hadoop.hive.common.LogUtils.initHiveLog4jCommon(ConfVars)",17,2,n/a,33,4,1,17,6
"org.apache.hadoop.hive.common.LogUtils.initHiveLog4jDefault(HiveConf,String,ConfVars)",13,2,n/a,30,2,3,19,6
"org.apache.hadoop.hive.common.LogUtils.logConfigLocation(HiveConf)",9,2,n/a,14,1,1,5,3
"org.apache.hadoop.hive.common.ObjectPair.ObjectPair()",0,0,n/a,1,0,0,0,1
"org.apache.hadoop.hive.common.ObjectPair.ObjectPair(F,S)",0,1,n/a,4,0,2,2,1
"org.apache.hadoop.hive.common.ObjectPair.create(T1,T2)",1,0,n/a,7,0,2,1,1
"org.apache.hadoop.hive.common.ObjectPair.equals(Object)",1,2,n/a,10,1,1,5,3
"org.apache.hadoop.hive.common.ObjectPair.equals(ObjectPair<F, S>)",6,1,n/a,7,1,1,3,3
"org.apache.hadoop.hive.common.ObjectPair.getFirst()",0,2,n/a,3,0,0,1,1
"org.apache.hadoop.hive.common.ObjectPair.getSecond()",0,2,n/a,3,0,0,1,1
"org.apache.hadoop.hive.common.ObjectPair.setFirst(F)",0,0,n/a,3,0,1,1,1
"org.apache.hadoop.hive.common.ObjectPair.setSecond(S)",0,0,n/a,3,0,1,1,1
"org.apache.hadoop.hive.common.ObjectPair.toString()",0,2,n/a,3,0,0,1,1
"org.apache.hadoop.hive.common.ServerUtils.cleanUpScratchDir(HiveConf)",7,0,n/a,15,2,1,8,3
"org.apache.hadoop.hive.common.StatsSetupConst.StatDB.getAggregator(Configuration)",n/a,0,5,n/a,n/a,1,n/a,n/a
"org.apache.hadoop.hive.common.StatsSetupConst.StatDB.getPublisher(Configuration)",n/a,0,5,n/a,n/a,1,n/a,n/a
"org.apache.hadoop.hive.common.StatsSetupConst.areStatsUptoDate(Map<String, String>)",2,0,n/a,4,0,1,2,2
"org.apache.hadoop.hive.common.ValidTxnList.getHighWatermark()",n/a,0,1,n/a,n/a,0,n/a,n/a
"org.apache.hadoop.hive.common.ValidTxnList.getOpenTransactions()",n/a,0,1,n/a,n/a,0,n/a,n/a
"org.apache.hadoop.hive.common.ValidTxnList.isTxnCommitted(long)",n/a,0,1,n/a,n/a,1,n/a,n/a
"org.apache.hadoop.hive.common.ValidTxnList.isTxnRangeCommitted(long,long)",n/a,0,1,n/a,n/a,2,n/a,n/a
"org.apache.hadoop.hive.common.ValidTxnList.readFromString(String)",n/a,1,1,n/a,n/a,1,n/a,n/a
"org.apache.hadoop.hive.common.ValidTxnList.writeToString()",n/a,1,1,n/a,n/a,0,n/a,n/a
"org.apache.hadoop.hive.common.ValidTxnListImpl.ValidTxnListImpl()",1,0,n/a,3,0,0,1,1
"org.apache.hadoop.hive.common.ValidTxnListImpl.ValidTxnListImpl(String)",1,0,n/a,3,0,1,1,1
"org.apache.hadoop.hive.common.ValidTxnListImpl.ValidTxnListImpl(long[],long)",2,1,n/a,9,1,2,5,2
"org.apache.hadoop.hive.common.ValidTxnListImpl.getHighWatermark()",0,0,n/a,4,0,0,1,1
"org.apache.hadoop.hive.common.ValidTxnListImpl.getOpenTransactions()",0,0,n/a,4,0,0,1,1
"org.apache.hadoop.hive.common.ValidTxnListImpl.isTxnCommitted(long)",1,0,n/a,7,1,1,3,2
"org.apache.hadoop.hive.common.ValidTxnListImpl.isTxnRangeCommitted(long,long)",1,0,n/a,24,2,2,13,9
"org.apache.hadoop.hive.common.ValidTxnListImpl.readFromString(String)",3,2,n/a,14,2,1,10,3
"org.apache.hadoop.hive.common.ValidTxnListImpl.toString()",1,2,n/a,4,0,0,1,1
"org.apache.hadoop.hive.common.ValidTxnListImpl.writeToString()",6,2,n/a,14,2,0,8,3
"org.apache.hadoop.hive.common.classification.InterfaceAudience.InterfaceAudience()",0,0,n/a,1,0,0,0,1
"org.apache.hadoop.hive.common.classification.InterfaceAudience.LimitedPrivate.value()",n/a,2,0,n/a,n/a,0,n/a,n/a
"org.apache.hadoop.hive.common.cli.CommonCliOptions.CommonCliOptions(String,boolean)",11,0,n/a,23,1,2,5,2
"org.apache.hadoop.hive.common.cli.CommonCliOptions.addHiveconfToSystemProperties()",6,0,n/a,17,2,0,6,3
"org.apache.hadoop.hive.common.cli.CommonCliOptions.isVerbose()",0,0,n/a,6,0,0,1,1
"org.apache.hadoop.hive.common.cli.CommonCliOptions.parse(String[])",10,0,n/a,20,2,1,10,4
"org.apache.hadoop.hive.common.cli.CommonCliOptions.printUsage()",2,2,n/a,6,0,0,1,1
"org.apache.hadoop.hive.common.cli.HiveFileProcessor.loadFile(String)",n/a,1,0,n/a,n/a,1,n/a,n/a
"org.apache.hadoop.hive.common.cli.HiveFileProcessor.processCmd(String)",n/a,1,0,n/a,n/a,1,n/a,n/a
"org.apache.hadoop.hive.common.cli.HiveFileProcessor.processFile(String)",3,0,n/a,9,1,1,5,1
"org.apache.hadoop.hive.common.cli.HiveFileProcessor.processLine(String)",6,1,n/a,26,2,1,14,5
"org.apache.hadoop.hive.common.cli.HiveFileProcessor.processReader(BufferedReader)",6,1,n/a,16,2,1,6,3
"org.apache.hadoop.hive.common.cli.IHiveFileProcessor.processFile(String)",n/a,0,1,n/a,n/a,1,n/a,n/a
"org.apache.hadoop.hive.common.cli.ShellCmdExecutor.ShellCmdExecutor(String,PrintStream,PrintStream)",0,0,n/a,5,0,3,3,1
"org.apache.hadoop.hive.common.cli.ShellCmdExecutor.execute()",12,0,n/a,15,1,0,11,2
"org.apache.hadoop.hive.common.io.CachingPrintStream.CachingPrintStream(OutputStream)",1,0,n/a,3,0,1,1,1
"org.apache.hadoop.hive.common.io.CachingPrintStream.CachingPrintStream(OutputStream,boolean,String)",1,0,n/a,4,0,3,1,1
"org.apache.hadoop.hive.common.io.CachingPrintStream.flush()",2,3,n/a,5,0,0,2,1
"org.apache.hadoop.hive.common.io.CachingPrintStream.getOutput()",0,0,n/a,3,0,0,1,1
"org.apache.hadoop.hive.common.io.CachingPrintStream.println(String)",2,10,n/a,5,0,1,2,1
"org.apache.hadoop.hive.common.io.DigestPrintStream.DigestPrintStream(OutputStream,String)",2,0,n/a,4,0,2,2,1
"org.apache.hadoop.hive.common.io.DigestPrintStream.process(String)",2,1,n/a,4,0,1,1,1
"org.apache.hadoop.hive.common.io.DigestPrintStream.processFinal()",5,1,n/a,5,0,0,2,1
"org.apache.hadoop.hive.common.io.FetchConverter.FetchConverter(OutputStream,boolean,String)",1,2,n/a,4,0,3,1,1
"org.apache.hadoop.hive.common.io.FetchConverter.byPass()",0,3,n/a,3,0,0,1,2
"org.apache.hadoop.hive.common.io.FetchConverter.fetchFinished()",3,0,n/a,7,1,0,4,2
"org.apache.hadoop.hive.common.io.FetchConverter.fetchStarted()",0,0,n/a,3,0,0,1,1
"org.apache.hadoop.hive.common.io.FetchConverter.flush()",2,3,n/a,6,1,0,2,2
"org.apache.hadoop.hive.common.io.FetchConverter.foundQuery(boolean)",0,0,n/a,3,0,1,1,1
"org.apache.hadoop.hive.common.io.FetchConverter.printDirect(String)",1,5,n/a,3,0,1,1,1
"org.apache.hadoop.hive.common.io.FetchConverter.println(String)",3,10,n/a,7,1,1,3,2
"org.apache.hadoop.hive.common.io.FetchConverter.process(String)",n/a,1,2,n/a,n/a,1,n/a,n/a
"org.apache.hadoop.hive.common.io.FetchConverter.processFinal()",n/a,1,3,n/a,n/a,0,n/a,n/a
"org.apache.hadoop.hive.common.io.NonSyncByteArrayInputStream.NonSyncByteArrayInputStream()",1,0,n/a,3,0,0,1,1
"org.apache.hadoop.hive.common.io.NonSyncByteArrayInputStream.NonSyncByteArrayInputStream(byte[])",1,0,n/a,3,0,1,1,1
"org.apache.hadoop.hive.common.io.NonSyncByteArrayInputStream.NonSyncByteArrayInputStream(byte[],int,int)",1,0,n/a,3,0,3,1,1
"org.apache.hadoop.hive.common.io.NonSyncByteArrayInputStream.available()",0,1,n/a,7,0,0,1,1
"org.apache.hadoop.hive.common.io.NonSyncByteArrayInputStream.getLength()",0,0,n/a,3,0,0,1,1
"org.apache.hadoop.hive.common.io.NonSyncByteArrayInputStream.getPosition()",0,0,n/a,3,0,0,1,1
"org.apache.hadoop.hive.common.io.NonSyncByteArrayInputStream.read()",0,1,n/a,7,0,0,1,2
"org.apache.hadoop.hive.common.io.NonSyncByteArrayInputStream.read(byte[],int,int)",3,1,n/a,23,1,3,13,8
"org.apache.hadoop.hive.common.io.NonSyncByteArrayInputStream.reset(byte[],int,int)",0,0,n/a,6,0,3,4,1
"org.apache.hadoop.hive.common.io.NonSyncByteArrayInputStream.skip(long)",0,1,n/a,14,1,1,6,3
"org.apache.hadoop.hive.common.io.NonSyncByteArrayOutputStream.NonSyncByteArrayOutputStream()",1,0,n/a,3,0,0,1,1
"org.apache.hadoop.hive.common.io.NonSyncByteArrayOutputStream.NonSyncByteArrayOutputStream(int)",1,0,n/a,3,0,1,1,1
"org.apache.hadoop.hive.common.io.NonSyncByteArrayOutputStream.enLargeBuffer(int)",1,3,n/a,13,2,1,9,3
"org.apache.hadoop.hive.common.io.NonSyncByteArrayOutputStream.getData()",0,0,n/a,3,0,0,1,1
"org.apache.hadoop.hive.common.io.NonSyncByteArrayOutputStream.getLength()",0,0,n/a,3,0,0,1,1
"org.apache.hadoop.hive.common.io.NonSyncByteArrayOutputStream.reset()",0,0,n/a,7,0,0,1,1
"org.apache.hadoop.hive.common.io.NonSyncByteArrayOutputStream.write(DataInput,int)",2,0,n/a,5,0,2,3,1
"org.apache.hadoop.hive.common.io.NonSyncByteArrayOutputStream.write(byte[],int,int)",3,1,n/a,15,1,3,7,7
"org.apache.hadoop.hive.common.io.NonSyncByteArrayOutputStream.write(int)",1,0,n/a,9,0,1,3,1
"org.apache.hadoop.hive.common.io.NonSyncByteArrayOutputStream.writeTo(OutputStream)",1,0,n/a,7,0,1,1,1
"org.apache.hadoop.hive.common.io.SortAndDigestPrintStream.SortAndDigestPrintStream(OutputStream,String)",2,0,n/a,4,0,2,2,1
"org.apache.hadoop.hive.common.io.SortAndDigestPrintStream.processFinal()",10,1,n/a,10,1,0,6,2
"org.apache.hadoop.hive.common.io.SortPrintStream.SortPrintStream(OutputStream,String)",1,1,n/a,3,0,2,1,1
"org.apache.hadoop.hive.common.io.SortPrintStream.process(String)",1,1,n/a,5,0,1,2,1
"org.apache.hadoop.hive.common.io.SortPrintStream.processFinal()",3,1,n/a,6,1,0,2,2
"org.apache.hadoop.hive.common.metrics.Metrics.Metrics()",0,0,n/a,3,0,0,0,1
"org.apache.hadoop.hive.common.metrics.Metrics.MetricsScope.MetricsScope(String)",1,1,n/a,12,0,1,5,1
"org.apache.hadoop.hive.common.metrics.Metrics.MetricsScope.close()",8,2,n/a,19,3,0,9,4
"org.apache.hadoop.hive.common.metrics.Metrics.MetricsScope.getNumCounter()",1,0,n/a,3,0,0,1,1
"org.apache.hadoop.hive.common.metrics.Metrics.MetricsScope.getTimeCounter()",1,0,n/a,3,0,0,1,1
"org.apache.hadoop.hive.common.metrics.Metrics.MetricsScope.open()",2,3,n/a,13,1,0,4,2
"org.apache.hadoop.hive.common.metrics.Metrics.MetricsScope.reopen()",2,0,n/a,10,1,0,3,2
"org.apache.hadoop.hive.common.metrics.Metrics.endScope(String)",5,0,n/a,8,1,1,4,3
"org.apache.hadoop.hive.common.metrics.Metrics.get(String)",1,3,n/a,6,1,1,3,2
"org.apache.hadoop.hive.common.metrics.Metrics.getScope(String)",5,0,n/a,10,1,1,5,3
"org.apache.hadoop.hive.common.metrics.Metrics.incrementCounter(String)",2,1,n/a,6,1,1,3,2
"org.apache.hadoop.hive.common.metrics.Metrics.incrementCounter(String,long)",5,2,n/a,16,2,2,10,3
"org.apache.hadoop.hive.common.metrics.Metrics.init()",2,0,n/a,9,2,0,5,2
"org.apache.hadoop.hive.common.metrics.Metrics.set(String,Object)",1,3,n/a,6,1,2,3,2
"org.apache.hadoop.hive.common.metrics.Metrics.startScope(String)",10,0,n/a,11,1,1,6,3
"org.apache.hadoop.hive.common.metrics.Metrics.uninit()",4,0,n/a,18,3,0,7,3
"org.apache.hadoop.hive.common.metrics.MetricsMBean.clear()",n/a,1,1,n/a,n/a,0,n/a,n/a
"org.apache.hadoop.hive.common.metrics.MetricsMBean.get(String)",n/a,1,1,n/a,n/a,1,n/a,n/a
"org.apache.hadoop.hive.common.metrics.MetricsMBean.hasKey(String)",n/a,1,1,n/a,n/a,1,n/a,n/a
"org.apache.hadoop.hive.common.metrics.MetricsMBean.put(String,Object)",n/a,1,1,n/a,n/a,2,n/a,n/a
"org.apache.hadoop.hive.common.metrics.MetricsMBeanImpl.clear()",1,1,n/a,8,1,0,4,1
"org.apache.hadoop.hive.common.metrics.MetricsMBeanImpl.get(String)",4,1,n/a,12,1,1,5,4
"org.apache.hadoop.hive.common.metrics.MetricsMBeanImpl.getAttribute(String)",3,1,n/a,11,2,1,4,2
"org.apache.hadoop.hive.common.metrics.MetricsMBeanImpl.getAttributes(String[])",4,0,n/a,10,2,1,5,2
"org.apache.hadoop.hive.common.metrics.MetricsMBeanImpl.getMBeanInfo()",9,0,n/a,18,3,0,9,3
"org.apache.hadoop.hive.common.metrics.MetricsMBeanImpl.hasKey(String)",1,1,n/a,6,1,1,2,1
"org.apache.hadoop.hive.common.metrics.MetricsMBeanImpl.invoke(String,Object[],String[])",4,0,n/a,9,1,3,4,2
"org.apache.hadoop.hive.common.metrics.MetricsMBeanImpl.put(String,Object)",2,2,n/a,9,2,2,4,2
"org.apache.hadoop.hive.common.metrics.MetricsMBeanImpl.reset()",3,1,n/a,7,2,0,3,2
"org.apache.hadoop.hive.common.metrics.MetricsMBeanImpl.setAttribute(Attribute)",4,1,n/a,9,1,1,3,2
"org.apache.hadoop.hive.common.metrics.MetricsMBeanImpl.setAttributes(AttributeList)",4,0,n/a,20,2,1,6,6
"org.apache.hadoop.hive.common.type.Decimal128.Decimal128()",1,5,n/a,7,0,0,4,1
"org.apache.hadoop.hive.common.type.Decimal128.Decimal128(Decimal128)",1,0,n/a,12,0,1,4,1
"org.apache.hadoop.hive.common.type.Decimal128.Decimal128(String,short)",2,0,n/a,12,0,2,2,1
"org.apache.hadoop.hive.common.type.Decimal128.Decimal128(UnsignedInt128,short,boolean)",4,2,n/a,24,1,3,8,3
"org.apache.hadoop.hive.common.type.Decimal128.Decimal128(char[],int,int,short)",2,0,n/a,16,0,4,2,1
"org.apache.hadoop.hive.common.type.Decimal128.Decimal128(double,short)",2,0,n/a,20,0,2,2,1
"org.apache.hadoop.hive.common.type.Decimal128.Decimal128(long)",1,0,n/a,10,0,1,1,1
"org.apache.hadoop.hive.common.type.Decimal128.Decimal128(long,short)",2,1,n/a,12,0,2,2,1
"org.apache.hadoop.hive.common.type.Decimal128.absDestructive()",0,0,n/a,9,1,0,2,2
"org.apache.hadoop.hive.common.type.Decimal128.add(Decimal128,Decimal128,Decimal128,short)",2,0,n/a,24,0,4,2,1
"org.apache.hadoop.hive.common.type.Decimal128.addDestructive(Decimal128,short)",6,4,n/a,42,2,2,17,6
"org.apache.hadoop.hive.common.type.Decimal128.changeScaleDestructive(short)",5,6,n/a,43,2,1,13,5
"org.apache.hadoop.hive.common.type.Decimal128.checkPrecisionOverflow(int)",3,0,n/a,16,1,1,4,4
"org.apache.hadoop.hive.common.type.Decimal128.checkScaleRange(short)",2,3,n/a,15,1,1,4,3
"org.apache.hadoop.hive.common.type.Decimal128.compareTo(Decimal128)",2,2,n/a,35,1,1,9,4
"org.apache.hadoop.hive.common.type.Decimal128.divide(Decimal128,Decimal128,Decimal128,short)",3,1,n/a,28,1,4,4,3
"org.apache.hadoop.hive.common.type.Decimal128.divideDestructive(Decimal128,short)",10,1,n/a,22,1,2,7,2
"org.apache.hadoop.hive.common.type.Decimal128.divideDestructiveNativeDecimal128(Decimal128,short,Decimal128)",9,0,n/a,62,1,3,19,6
"org.apache.hadoop.hive.common.type.Decimal128.doubleValue()",2,2,n/a,18,0,0,1,1
"org.apache.hadoop.hive.common.type.Decimal128.equals(Object)",1,3,n/a,33,1,1,10,5
"org.apache.hadoop.hive.common.type.Decimal128.fastSerializeForHiveDecimal(Decimal128FastBuffer)",1,0,n/a,7,0,1,1,1
"org.apache.hadoop.hive.common.type.Decimal128.fastUpdateFromInternalStorage(byte[],short)",1,0,n/a,11,0,2,4,1
"org.apache.hadoop.hive.common.type.Decimal128.floatValue()",2,0,n/a,18,0,0,1,1
"org.apache.hadoop.hive.common.type.Decimal128.getHiveDecimalString()",12,2,n/a,51,4,0,36,12
"org.apache.hadoop.hive.common.type.Decimal128.getIntsPerElement(int)",1,0,n/a,11,0,1,1,1
"org.apache.hadoop.hive.common.type.Decimal128.getScale()",0,7,n/a,9,0,0,1,1
"org.apache.hadoop.hive.common.type.Decimal128.getSignum()",0,1,n/a,9,0,0,1,1
"org.apache.hadoop.hive.common.type.Decimal128.getUnscaledValue()",0,4,n/a,10,0,0,1,1
"org.apache.hadoop.hive.common.type.Decimal128.hashCode()",1,2,n/a,16,1,0,3,2
"org.apache.hadoop.hive.common.type.Decimal128.intValue()",5,0,n/a,28,1,0,9,3
"org.apache.hadoop.hive.common.type.Decimal128.isZero()",2,0,n/a,6,0,0,2,4
"org.apache.hadoop.hive.common.type.Decimal128.longValue()",5,0,n/a,34,2,0,12,4
"org.apache.hadoop.hive.common.type.Decimal128.modulo(Decimal128,Decimal128,Decimal128,short)",5,0,n/a,31,0,4,5,1
"org.apache.hadoop.hive.common.type.Decimal128.multiply(Decimal128,Decimal128,Decimal128,short)",3,0,n/a,28,1,4,4,3
"org.apache.hadoop.hive.common.type.Decimal128.multiplyDestructive(Decimal128,short)",10,4,n/a,23,1,2,7,2
"org.apache.hadoop.hive.common.type.Decimal128.multiplyDestructiveNativeDecimal128(Decimal128,short)",6,0,n/a,51,1,2,17,5
"org.apache.hadoop.hive.common.type.Decimal128.negateDestructive()",0,2,n/a,7,0,0,1,1
"org.apache.hadoop.hive.common.type.Decimal128.powAsDouble(double)",5,0,n/a,47,1,1,7,4
"org.apache.hadoop.hive.common.type.Decimal128.serializeTo(IntBuffer,int)",2,0,n/a,13,0,2,2,1
"org.apache.hadoop.hive.common.type.Decimal128.serializeTo(int[],int,int)",1,0,n/a,15,0,3,2,1
"org.apache.hadoop.hive.common.type.Decimal128.serializeTo128(IntBuffer)",2,0,n/a,11,0,1,2,1
"org.apache.hadoop.hive.common.type.Decimal128.serializeTo128(int[],int)",1,0,n/a,13,0,2,2,1
"org.apache.hadoop.hive.common.type.Decimal128.serializeTo32(IntBuffer)",2,0,n/a,11,0,1,2,1
"org.apache.hadoop.hive.common.type.Decimal128.serializeTo32(int[],int)",1,0,n/a,13,0,2,2,1
"org.apache.hadoop.hive.common.type.Decimal128.serializeTo64(IntBuffer)",2,0,n/a,11,0,1,2,1
"org.apache.hadoop.hive.common.type.Decimal128.serializeTo64(int[],int)",1,0,n/a,13,0,2,2,1
"org.apache.hadoop.hive.common.type.Decimal128.serializeTo96(IntBuffer)",2,0,n/a,11,0,1,2,1
"org.apache.hadoop.hive.common.type.Decimal128.serializeTo96(int[],int)",1,0,n/a,13,0,2,2,1
"org.apache.hadoop.hive.common.type.Decimal128.setNullDataValue()",1,0,n/a,8,0,0,1,1
"org.apache.hadoop.hive.common.type.Decimal128.setScale(short)",0,0,n/a,6,0,1,1,1
"org.apache.hadoop.hive.common.type.Decimal128.setSignum(byte)",0,0,n/a,6,0,1,1,1
"org.apache.hadoop.hive.common.type.Decimal128.setUnscaledValue(UnsignedInt128)",0,0,n/a,6,0,1,1,1
"org.apache.hadoop.hive.common.type.Decimal128.sqrtAsDouble()",3,0,n/a,38,1,0,6,3
"org.apache.hadoop.hive.common.type.Decimal128.squareDestructive()",2,1,n/a,9,0,0,2,1
"org.apache.hadoop.hive.common.type.Decimal128.subtract(Decimal128,Decimal128,Decimal128,short)",2,0,n/a,24,0,4,2,1
"org.apache.hadoop.hive.common.type.Decimal128.subtractDestructive(Decimal128,short)",7,3,n/a,44,2,2,18,6
"org.apache.hadoop.hive.common.type.Decimal128.toBigDecimal()",2,6,n/a,10,0,0,1,1
"org.apache.hadoop.hive.common.type.Decimal128.toFormalString()",16,4,n/a,39,3,0,20,7
"org.apache.hadoop.hive.common.type.Decimal128.toString()",4,3,n/a,7,0,0,1,1
"org.apache.hadoop.hive.common.type.Decimal128.update(BigDecimal)",3,0,n/a,8,0,1,1,1
"org.apache.hadoop.hive.common.type.Decimal128.update(BigInteger,short)",5,1,n/a,20,1,2,9,3
"org.apache.hadoop.hive.common.type.Decimal128.update(Decimal128)",1,8,n/a,13,0,1,5,1
"org.apache.hadoop.hive.common.type.Decimal128.update(Decimal128,short)",2,0,n/a,11,0,2,3,1
"org.apache.hadoop.hive.common.type.Decimal128.update(IntBuffer,int)",3,0,n/a,18,0,2,7,1
"org.apache.hadoop.hive.common.type.Decimal128.update(String,short)",3,3,n/a,11,0,2,1,1
"org.apache.hadoop.hive.common.type.Decimal128.update(char[],int,int,short)",12,2,n/a,110,4,4,66,27
"org.apache.hadoop.hive.common.type.Decimal128.update(double,short)",14,1,n/a,90,2,2,29,11
"org.apache.hadoop.hive.common.type.Decimal128.update(int[],int,int)",1,0,n/a,19,0,3,6,1
"org.apache.hadoop.hive.common.type.Decimal128.update(long)",1,3,n/a,10,0,1,1,1
"org.apache.hadoop.hive.common.type.Decimal128.update(long,short)",4,2,n/a,27,1,2,12,4
"org.apache.hadoop.hive.common.type.Decimal128.update128(IntBuffer)",3,0,n/a,16,0,1,7,1
"org.apache.hadoop.hive.common.type.Decimal128.update128(int[],int)",1,0,n/a,17,0,2,6,1
"org.apache.hadoop.hive.common.type.Decimal128.update32(IntBuffer)",3,0,n/a,16,0,1,7,1
"org.apache.hadoop.hive.common.type.Decimal128.update32(int[],int)",1,0,n/a,17,0,2,6,1
"org.apache.hadoop.hive.common.type.Decimal128.update64(IntBuffer)",3,0,n/a,16,0,1,7,1
"org.apache.hadoop.hive.common.type.Decimal128.update64(int[],int)",1,0,n/a,17,0,2,6,1
"org.apache.hadoop.hive.common.type.Decimal128.update96(IntBuffer)",3,0,n/a,16,0,1,7,1
"org.apache.hadoop.hive.common.type.Decimal128.update96(int[],int)",1,0,n/a,17,0,2,6,1
"org.apache.hadoop.hive.common.type.Decimal128.updateFixedPoint(long,short)",3,0,n/a,20,1,2,8,3
"org.apache.hadoop.hive.common.type.Decimal128.updateVarianceDestructive(Decimal128,Decimal128,Decimal128,long)",9,0,n/a,28,0,4,7,1
"org.apache.hadoop.hive.common.type.Decimal128.zeroClear()",1,5,n/a,6,0,0,3,1
"org.apache.hadoop.hive.common.type.Decimal128.zeroFractionPart()",2,1,n/a,7,0,0,2,1
"org.apache.hadoop.hive.common.type.Decimal128.zeroFractionPart(UnsignedInt128)",6,1,n/a,25,1,1,8,3
"org.apache.hadoop.hive.common.type.HiveBaseChar.HiveBaseChar()",0,6,n/a,2,0,0,0,1
"org.apache.hadoop.hive.common.type.HiveBaseChar.enforceMaxLength(String,int)",4,2,n/a,12,2,2,6,3
"org.apache.hadoop.hive.common.type.HiveBaseChar.getCharacterLength()",2,0,n/a,3,0,0,1,1
"org.apache.hadoop.hive.common.type.HiveBaseChar.getPaddedValue(String,int)",5,1,n/a,16,1,2,9,4
"org.apache.hadoop.hive.common.type.HiveBaseChar.getValue()",0,7,n/a,3,0,0,1,1
"org.apache.hadoop.hive.common.type.HiveBaseChar.hashCode()",2,1,n/a,4,0,0,1,1
"org.apache.hadoop.hive.common.type.HiveBaseChar.setValue(HiveBaseChar,int)",1,1,n/a,3,0,2,1,1
"org.apache.hadoop.hive.common.type.HiveBaseChar.setValue(String,int)",1,5,n/a,7,0,2,1,1
"org.apache.hadoop.hive.common.type.HiveBaseChar.toString()",1,2,n/a,4,0,0,1,1
"org.apache.hadoop.hive.common.type.HiveChar.HiveChar()",0,0,n/a,2,0,0,0,1
"org.apache.hadoop.hive.common.type.HiveChar.HiveChar(HiveChar,int)",1,0,n/a,3,0,2,1,1
"org.apache.hadoop.hive.common.type.HiveChar.HiveChar(String,int)",1,0,n/a,3,0,2,1,1
"org.apache.hadoop.hive.common.type.HiveChar.compareTo(HiveChar)",3,0,n/a,6,1,1,3,2
"org.apache.hadoop.hive.common.type.HiveChar.equals(Object)",5,2,n/a,9,1,1,5,4
"org.apache.hadoop.hive.common.type.HiveChar.getCharacterLength()",3,0,n/a,4,0,0,2,1
"org.apache.hadoop.hive.common.type.HiveChar.getPaddedValue()",0,1,n/a,3,0,0,1,1
"org.apache.hadoop.hive.common.type.HiveChar.getStrippedValue()",1,6,n/a,3,0,0,1,1
"org.apache.hadoop.hive.common.type.HiveChar.hashCode()",2,1,n/a,3,0,0,1,1
"org.apache.hadoop.hive.common.type.HiveChar.setValue(String)",1,0,n/a,3,0,1,1,1
"org.apache.hadoop.hive.common.type.HiveChar.setValue(String,int)",2,8,n/a,6,0,2,1,1
"org.apache.hadoop.hive.common.type.HiveChar.toString()",1,2,n/a,3,0,0,1,1
"org.apache.hadoop.hive.common.type.HiveDecimal.HiveDecimal(BigDecimal)",0,10,n/a,3,0,1,1,1
"org.apache.hadoop.hive.common.type.HiveDecimal.abs()",2,0,n/a,3,0,0,1,1
"org.apache.hadoop.hive.common.type.HiveDecimal.add(HiveDecimal)",2,0,n/a,3,0,1,1,1
"org.apache.hadoop.hive.common.type.HiveDecimal.bigDecimalValue()",0,2,n/a,3,0,0,1,1
"org.apache.hadoop.hive.common.type.HiveDecimal.byteValue()",1,0,n/a,3,0,0,1,1
"org.apache.hadoop.hive.common.type.HiveDecimal.compareTo(HiveDecimal)",1,0,n/a,4,0,1,1,1
"org.apache.hadoop.hive.common.type.HiveDecimal.create(BigDecimal)",1,12,n/a,3,0,1,1,1
"org.apache.hadoop.hive.common.type.HiveDecimal.create(BigDecimal,boolean)",2,3,n/a,4,0,2,2,2
"org.apache.hadoop.hive.common.type.HiveDecimal.create(BigInteger)",3,0,n/a,4,0,1,2,2
"org.apache.hadoop.hive.common.type.HiveDecimal.create(BigInteger,int)",3,0,n/a,4,0,2,2,2
"org.apache.hadoop.hive.common.type.HiveDecimal.create(String)",3,0,n/a,10,1,1,6,3
"org.apache.hadoop.hive.common.type.HiveDecimal.create(int)",2,0,n/a,3,0,1,1,1
"org.apache.hadoop.hive.common.type.HiveDecimal.create(long)",2,0,n/a,3,0,1,1,1
"org.apache.hadoop.hive.common.type.HiveDecimal.divide(HiveDecimal)",3,1,n/a,3,0,1,1,1
"org.apache.hadoop.hive.common.type.HiveDecimal.doubleValue()",1,0,n/a,3,0,0,1,1
"org.apache.hadoop.hive.common.type.HiveDecimal.enforcePrecisionScale(BigDecimal,int,int)",4,0,n/a,14,1,3,9,4
"org.apache.hadoop.hive.common.type.HiveDecimal.equals(Object)",3,2,n/a,7,1,1,3,3
"org.apache.hadoop.hive.common.type.HiveDecimal.floatValue()",1,0,n/a,3,0,0,1,1
"org.apache.hadoop.hive.common.type.HiveDecimal.hashCode()",2,1,n/a,4,0,0,1,1
"org.apache.hadoop.hive.common.type.HiveDecimal.intValue()",1,0,n/a,3,0,0,1,1
"org.apache.hadoop.hive.common.type.HiveDecimal.longValue()",1,1,n/a,3,0,0,1,1
"org.apache.hadoop.hive.common.type.HiveDecimal.multiply(HiveDecimal)",2,1,n/a,3,0,1,1,1
"org.apache.hadoop.hive.common.type.HiveDecimal.negate()",2,0,n/a,3,0,0,1,1
"org.apache.hadoop.hive.common.type.HiveDecimal.normalize(BigDecimal,boolean)",7,5,n/a,18,2,2,11,5
"org.apache.hadoop.hive.common.type.HiveDecimal.pow(int)",3,0,n/a,4,0,1,2,2
"org.apache.hadoop.hive.common.type.HiveDecimal.precision()",1,0,n/a,3,0,0,1,1
"org.apache.hadoop.hive.common.type.HiveDecimal.remainder(HiveDecimal)",2,0,n/a,3,0,1,1,1
"org.apache.hadoop.hive.common.type.HiveDecimal.scale()",1,0,n/a,3,0,0,1,1
"org.apache.hadoop.hive.common.type.HiveDecimal.scaleByPowerOfTen(int)",2,0,n/a,3,0,1,1,1
"org.apache.hadoop.hive.common.type.HiveDecimal.setScale(int)",2,0,n/a,3,0,1,1,1
"org.apache.hadoop.hive.common.type.HiveDecimal.setScale(int,int)",2,0,n/a,3,0,2,1,1
"org.apache.hadoop.hive.common.type.HiveDecimal.shortValue()",1,0,n/a,3,0,0,1,1
"org.apache.hadoop.hive.common.type.HiveDecimal.signum()",1,0,n/a,7,0,0,1,1
"org.apache.hadoop.hive.common.type.HiveDecimal.subtract(HiveDecimal)",2,0,n/a,3,0,1,1,1
"org.apache.hadoop.hive.common.type.HiveDecimal.toString()",1,2,n/a,4,0,0,1,1
"org.apache.hadoop.hive.common.type.HiveDecimal.trim(BigDecimal)",4,2,n/a,13,2,1,6,3
"org.apache.hadoop.hive.common.type.HiveDecimal.unscaledValue()",1,0,n/a,3,0,0,1,1
"org.apache.hadoop.hive.common.type.HiveVarchar.HiveVarchar()",0,0,n/a,2,0,0,0,1
"org.apache.hadoop.hive.common.type.HiveVarchar.HiveVarchar(HiveVarchar,int)",1,0,n/a,3,0,2,1,1
"org.apache.hadoop.hive.common.type.HiveVarchar.HiveVarchar(String,int)",1,0,n/a,3,0,2,1,1
"org.apache.hadoop.hive.common.type.HiveVarchar.compareTo(HiveVarchar)",3,0,n/a,6,1,1,3,2
"org.apache.hadoop.hive.common.type.HiveVarchar.equals(HiveVarchar)",3,0,n/a,6,1,1,3,2
"org.apache.hadoop.hive.common.type.HiveVarchar.setValue(HiveVarchar)",2,0,n/a,3,0,1,1,1
"org.apache.hadoop.hive.common.type.HiveVarchar.setValue(String)",1,0,n/a,6,0,1,1,1
"org.apache.hadoop.hive.common.type.SignedInt128.SignedInt128()",1,2,n/a,7,0,0,2,1
"org.apache.hadoop.hive.common.type.SignedInt128.SignedInt128(SignedInt128)",1,0,n/a,10,0,1,2,1
"org.apache.hadoop.hive.common.type.SignedInt128.SignedInt128(String)",2,0,n/a,10,0,1,2,1
"org.apache.hadoop.hive.common.type.SignedInt128.SignedInt128(UnsignedInt128)",6,0,n/a,13,0,1,2,1
"org.apache.hadoop.hive.common.type.SignedInt128.SignedInt128(char[],int,int)",2,0,n/a,14,0,3,2,1
"org.apache.hadoop.hive.common.type.SignedInt128.SignedInt128(int,int,int,int)",1,2,n/a,17,0,4,2,1
"org.apache.hadoop.hive.common.type.SignedInt128.SignedInt128(long)",1,0,n/a,10,0,1,2,2
"org.apache.hadoop.hive.common.type.SignedInt128.abs(SignedInt128,SignedInt128)",2,0,n/a,13,0,2,2,1
"org.apache.hadoop.hive.common.type.SignedInt128.absDestructive()",0,1,n/a,6,0,0,1,1
"org.apache.hadoop.hive.common.type.SignedInt128.add(SignedInt128,SignedInt128,SignedInt128)",2,0,n/a,16,0,3,2,1
"org.apache.hadoop.hive.common.type.SignedInt128.addDestructive(SignedInt128)",4,1,n/a,18,2,1,7,4
"org.apache.hadoop.hive.common.type.SignedInt128.compareTo(SignedInt128)",2,0,n/a,16,2,1,7,4
"org.apache.hadoop.hive.common.type.SignedInt128.decrement(SignedInt128,SignedInt128)",2,0,n/a,13,0,2,2,1
"org.apache.hadoop.hive.common.type.SignedInt128.decrementDestructive()",7,1,n/a,21,2,0,9,4
"org.apache.hadoop.hive.common.type.SignedInt128.divide(SignedInt128,SignedInt128,SignedInt128,SignedInt128)",3,0,n/a,22,1,4,4,3
"org.apache.hadoop.hive.common.type.SignedInt128.divideDestructive(SignedInt128,SignedInt128)",1,1,n/a,13,0,2,3,1
"org.apache.hadoop.hive.common.type.SignedInt128.divideDestructive(int)",3,0,n/a,25,1,1,11,4
"org.apache.hadoop.hive.common.type.SignedInt128.doubleValue()",1,0,n/a,4,0,0,1,1
"org.apache.hadoop.hive.common.type.SignedInt128.equals(Object)",1,2,n/a,9,1,1,4,3
"org.apache.hadoop.hive.common.type.SignedInt128.equals(SignedInt128)",1,0,n/a,10,0,1,1,2
"org.apache.hadoop.hive.common.type.SignedInt128.floatValue()",1,0,n/a,4,0,0,1,1
"org.apache.hadoop.hive.common.type.SignedInt128.getIntsPerElement(int)",1,0,n/a,10,0,1,1,1
"org.apache.hadoop.hive.common.type.SignedInt128.getV0()",1,0,n/a,4,0,0,1,1
"org.apache.hadoop.hive.common.type.SignedInt128.getV1()",1,0,n/a,4,0,0,1,1
"org.apache.hadoop.hive.common.type.SignedInt128.getV2()",1,0,n/a,4,0,0,1,1
"org.apache.hadoop.hive.common.type.SignedInt128.getV3()",1,0,n/a,4,0,0,1,1
"org.apache.hadoop.hive.common.type.SignedInt128.hashCode()",2,1,n/a,4,0,0,1,2
"org.apache.hadoop.hive.common.type.SignedInt128.increment(SignedInt128,SignedInt128)",2,0,n/a,13,0,2,2,1
"org.apache.hadoop.hive.common.type.SignedInt128.incrementDestructive()",7,1,n/a,20,2,0,9,4
"org.apache.hadoop.hive.common.type.SignedInt128.intValue()",1,1,n/a,5,0,0,2,2
"org.apache.hadoop.hive.common.type.SignedInt128.isZero()",1,0,n/a,6,0,0,1,1
"org.apache.hadoop.hive.common.type.SignedInt128.longValue()",3,1,n/a,6,0,0,2,2
"org.apache.hadoop.hive.common.type.SignedInt128.multiply(SignedInt128,SignedInt128,SignedInt128)",3,0,n/a,20,1,3,4,3
"org.apache.hadoop.hive.common.type.SignedInt128.multiplyDestructive(SignedInt128)",3,1,n/a,13,1,1,4,2
"org.apache.hadoop.hive.common.type.SignedInt128.multiplyDestructive(int)",5,0,n/a,20,1,1,8,4
"org.apache.hadoop.hive.common.type.SignedInt128.negate(SignedInt128,SignedInt128)",2,0,n/a,13,0,2,2,1
"org.apache.hadoop.hive.common.type.SignedInt128.negateDestructive()",0,1,n/a,6,0,0,1,1
"org.apache.hadoop.hive.common.type.SignedInt128.scaleDownTen(SignedInt128,SignedInt128,short)",2,0,n/a,16,0,3,2,1
"org.apache.hadoop.hive.common.type.SignedInt128.scaleDownTenDestructive(short)",2,1,n/a,14,1,1,3,3
"org.apache.hadoop.hive.common.type.SignedInt128.scaleUpTen(SignedInt128,SignedInt128,short)",2,0,n/a,16,0,3,2,1
"org.apache.hadoop.hive.common.type.SignedInt128.scaleUpTenDestructive(short)",3,1,n/a,15,1,1,3,2
"org.apache.hadoop.hive.common.type.SignedInt128.serializeTo128(IntBuffer)",9,0,n/a,15,0,1,5,2
"org.apache.hadoop.hive.common.type.SignedInt128.serializeTo128(int[],int)",5,0,n/a,17,0,2,5,2
"org.apache.hadoop.hive.common.type.SignedInt128.serializeTo32(IntBuffer)",6,0,n/a,13,0,1,2,5
"org.apache.hadoop.hive.common.type.SignedInt128.serializeTo32(int[],int)",5,0,n/a,15,0,2,2,5
"org.apache.hadoop.hive.common.type.SignedInt128.serializeTo64(IntBuffer)",7,0,n/a,13,0,1,3,4
"org.apache.hadoop.hive.common.type.SignedInt128.serializeTo64(int[],int)",5,0,n/a,15,0,2,3,4
"org.apache.hadoop.hive.common.type.SignedInt128.serializeTo96(IntBuffer)",8,0,n/a,14,0,1,4,3
"org.apache.hadoop.hive.common.type.SignedInt128.serializeTo96(int[],int)",5,0,n/a,16,0,2,4,3
"org.apache.hadoop.hive.common.type.SignedInt128.shiftLeft(SignedInt128,SignedInt128,int)",2,0,n/a,15,0,3,2,1
"org.apache.hadoop.hive.common.type.SignedInt128.shiftLeftDestructive(int)",4,1,n/a,16,1,1,4,2
"org.apache.hadoop.hive.common.type.SignedInt128.shiftRight(SignedInt128,SignedInt128,int,boolean)",2,0,n/a,18,0,4,2,1
"org.apache.hadoop.hive.common.type.SignedInt128.shiftRightDestructive(int,boolean)",2,1,n/a,18,1,2,3,3
"org.apache.hadoop.hive.common.type.SignedInt128.subtract(SignedInt128,SignedInt128,SignedInt128)",2,0,n/a,16,0,3,2,1
"org.apache.hadoop.hive.common.type.SignedInt128.subtractDestructive(SignedInt128)",4,1,n/a,18,2,1,7,4
"org.apache.hadoop.hive.common.type.SignedInt128.toBigIntegerSlow()",2,0,n/a,10,0,0,2,2
"org.apache.hadoop.hive.common.type.SignedInt128.toFormalString()",2,0,n/a,14,1,0,3,2
"org.apache.hadoop.hive.common.type.SignedInt128.toString()",1,3,n/a,5,0,0,1,2
"org.apache.hadoop.hive.common.type.SignedInt128.update(SignedInt128)",1,12,n/a,10,0,1,2,1
"org.apache.hadoop.hive.common.type.SignedInt128.update(String)",3,1,n/a,9,0,1,1,1
"org.apache.hadoop.hive.common.type.SignedInt128.update(char[],int,int)",3,2,n/a,30,1,3,14,5
"org.apache.hadoop.hive.common.type.SignedInt128.update(long)",1,0,n/a,10,0,1,2,2
"org.apache.hadoop.hive.common.type.SignedInt128.update128(IntBuffer)",5,0,n/a,10,0,1,1,1
"org.apache.hadoop.hive.common.type.SignedInt128.update128(int,int,int,int)",1,2,n/a,17,0,4,2,1
"org.apache.hadoop.hive.common.type.SignedInt128.update128(int[],int)",1,0,n/a,13,0,2,1,1
"org.apache.hadoop.hive.common.type.SignedInt128.update32(IntBuffer)",2,0,n/a,10,0,1,1,1
"org.apache.hadoop.hive.common.type.SignedInt128.update32(int)",1,2,n/a,10,0,1,2,1
"org.apache.hadoop.hive.common.type.SignedInt128.update32(int[],int)",1,0,n/a,12,0,2,1,1
"org.apache.hadoop.hive.common.type.SignedInt128.update64(IntBuffer)",3,0,n/a,10,0,1,1,1
"org.apache.hadoop.hive.common.type.SignedInt128.update64(int,int)",1,2,n/a,12,0,2,2,1
"org.apache.hadoop.hive.common.type.SignedInt128.update64(int[],int)",1,0,n/a,12,0,2,1,1
"org.apache.hadoop.hive.common.type.SignedInt128.update96(IntBuffer)",4,0,n/a,10,0,1,1,1
"org.apache.hadoop.hive.common.type.SignedInt128.update96(int,int,int)",1,2,n/a,14,0,3,2,1
"org.apache.hadoop.hive.common.type.SignedInt128.update96(int[],int)",1,0,n/a,12,0,2,1,1
"org.apache.hadoop.hive.common.type.SignedInt128.zeroClear()",1,1,n/a,5,0,0,2,1
"org.apache.hadoop.hive.common.type.SqlMathUtil.SqlMathUtil()",0,0,n/a,2,0,0,0,1
"org.apache.hadoop.hive.common.type.SqlMathUtil.arrayValidLength(int[])",0,2,n/a,10,1,1,4,4
"org.apache.hadoop.hive.common.type.SqlMathUtil.bitLength(int,int,int,int)",4,1,n/a,25,1,4,7,4
"org.apache.hadoop.hive.common.type.SqlMathUtil.bitLengthInWord(int)",0,4,n/a,25,2,1,9,5
"org.apache.hadoop.hive.common.type.SqlMathUtil.combineInts(int,int)",0,3,n/a,10,0,2,1,1
"org.apache.hadoop.hive.common.type.SqlMathUtil.compareUnsignedInt(int,int)",0,8,n/a,26,1,2,5,3
"org.apache.hadoop.hive.common.type.SqlMathUtil.compareUnsignedLong(long,long)",0,6,n/a,25,1,2,5,3
"org.apache.hadoop.hive.common.type.SqlMathUtil.divideMultiPrecision(int[],int)",0,2,n/a,19,1,2,11,2
"org.apache.hadoop.hive.common.type.SqlMathUtil.divideMultiPrecision(int[],int[],int[])",24,2,n/a,111,3,3,67,13
"org.apache.hadoop.hive.common.type.SqlMathUtil.divideUnsignedLong(long,long)",2,1,n/a,36,2,2,9,5
"org.apache.hadoop.hive.common.type.SqlMathUtil.extractHiInt(long)",0,4,n/a,8,0,1,1,1
"org.apache.hadoop.hive.common.type.SqlMathUtil.extractLowInt(long)",0,4,n/a,8,0,1,1,1
"org.apache.hadoop.hive.common.type.SqlMathUtil.multiplyMultiPrecision(int[],int)",1,2,n/a,18,1,2,9,3
"org.apache.hadoop.hive.common.type.SqlMathUtil.remainderUnsignedLong(long,long)",2,0,n/a,33,2,2,9,5
"org.apache.hadoop.hive.common.type.SqlMathUtil.setSignBitInt(int,boolean)",0,1,n/a,15,1,2,3,2
"org.apache.hadoop.hive.common.type.SqlMathUtil.setSignBitLong(long,boolean)",0,0,n/a,15,1,2,3,2
"org.apache.hadoop.hive.common.type.SqlMathUtil.throwOverflowException()",1,32,n/a,4,0,0,1,1
"org.apache.hadoop.hive.common.type.SqlMathUtil.throwZeroDivisionException()",1,3,n/a,4,0,0,1,1
"org.apache.hadoop.hive.common.type.UnsignedInt128.UnsignedInt128()",1,2,n/a,4,0,0,1,1
"org.apache.hadoop.hive.common.type.UnsignedInt128.UnsignedInt128(BigInteger)",1,0,n/a,9,0,1,1,1
"org.apache.hadoop.hive.common.type.UnsignedInt128.UnsignedInt128(String)",1,0,n/a,9,0,1,1,1
"org.apache.hadoop.hive.common.type.UnsignedInt128.UnsignedInt128(UnsignedInt128)",1,20,n/a,9,0,1,1,1
"org.apache.hadoop.hive.common.type.UnsignedInt128.UnsignedInt128(char[],int,int)",1,0,n/a,13,0,3,1,1
"org.apache.hadoop.hive.common.type.UnsignedInt128.UnsignedInt128(int,int,int,int)",1,8,n/a,15,0,4,1,1
"org.apache.hadoop.hive.common.type.UnsignedInt128.UnsignedInt128(long)",1,5,n/a,9,0,1,1,1
"org.apache.hadoop.hive.common.type.UnsignedInt128.addConstructive(UnsignedInt128)",2,0,n/a,13,0,1,3,1
"org.apache.hadoop.hive.common.type.UnsignedInt128.addDestructive(UnsignedInt128)",1,4,n/a,10,0,1,1,1
"org.apache.hadoop.hive.common.type.UnsignedInt128.addDestructive(int)",2,4,n/a,30,4,1,13,5
"org.apache.hadoop.hive.common.type.UnsignedInt128.addDestructive(int[])",2,2,n/a,19,1,1,9,3
"org.apache.hadoop.hive.common.type.UnsignedInt128.addDestructiveScaleTen(UnsignedInt128,short)",6,2,n/a,29,2,2,11,5
"org.apache.hadoop.hive.common.type.UnsignedInt128.asLong()",1,0,n/a,12,1,0,3,3
"org.apache.hadoop.hive.common.type.UnsignedInt128.bitLength()",1,1,n/a,3,0,0,1,1
"org.apache.hadoop.hive.common.type.UnsignedInt128.clone()",1,0,n/a,4,0,0,1,1
"org.apache.hadoop.hive.common.type.UnsignedInt128.compareTo(UnsignedInt128)",1,8,n/a,4,0,1,1,1
"org.apache.hadoop.hive.common.type.UnsignedInt128.compareTo(int,int,int,int)",4,1,n/a,24,1,4,7,4
"org.apache.hadoop.hive.common.type.UnsignedInt128.compareTo(int,int,int,int,int,int,int,int)",4,1,n/a,19,1,8,9,5
"org.apache.hadoop.hive.common.type.UnsignedInt128.compareTo(int[])",1,3,n/a,10,0,1,1,1
"org.apache.hadoop.hive.common.type.UnsignedInt128.compareToScaleTen(UnsignedInt128,short)",12,2,n/a,84,4,2,31,16
"org.apache.hadoop.hive.common.type.UnsignedInt128.decrementArray(int[])",1,1,n/a,12,2,1,9,4
"org.apache.hadoop.hive.common.type.UnsignedInt128.decrementConstructive()",2,0,n/a,12,0,0,3,1
"org.apache.hadoop.hive.common.type.UnsignedInt128.decrementDestructive()",2,3,n/a,8,0,0,2,1
"org.apache.hadoop.hive.common.type.UnsignedInt128.difference(UnsignedInt128,UnsignedInt128,UnsignedInt128)",1,3,n/a,19,0,3,1,1
"org.apache.hadoop.hive.common.type.UnsignedInt128.differenceInternal(UnsignedInt128,int[],UnsignedInt128)",4,2,n/a,30,2,3,20,7
"org.apache.hadoop.hive.common.type.UnsignedInt128.differenceScaleTen(UnsignedInt128,UnsignedInt128,UnsignedInt128,short)",6,2,n/a,37,2,4,9,4
"org.apache.hadoop.hive.common.type.UnsignedInt128.divideCheckRound(int[],int)",0,3,n/a,9,1,2,8,2
"org.apache.hadoop.hive.common.type.UnsignedInt128.divideConstructive(UnsignedInt128,UnsignedInt128)",2,0,n/a,16,0,2,3,1
"org.apache.hadoop.hive.common.type.UnsignedInt128.divideConstructive(int)",2,0,n/a,14,0,1,3,1
"org.apache.hadoop.hive.common.type.UnsignedInt128.divideDestructive(UnsignedInt128,UnsignedInt128)",8,4,n/a,27,1,2,14,3
"org.apache.hadoop.hive.common.type.UnsignedInt128.divideDestructive(int)",1,7,n/a,22,1,1,13,2
"org.apache.hadoop.hive.common.type.UnsignedInt128.divideDestructive(long)",1,1,n/a,21,1,1,12,2
"org.apache.hadoop.hive.common.type.UnsignedInt128.divideScaleUpTenDestructive(UnsignedInt128,short,UnsignedInt128)",5,1,n/a,26,1,3,7,2
"org.apache.hadoop.hive.common.type.UnsignedInt128.equals(Object)",1,4,n/a,7,1,1,3,2
"org.apache.hadoop.hive.common.type.UnsignedInt128.equals(UnsignedInt128)",0,4,n/a,12,0,1,1,4
"org.apache.hadoop.hive.common.type.UnsignedInt128.equals(int,int,int,int)",0,2,n/a,18,0,4,1,4
"org.apache.hadoop.hive.common.type.UnsignedInt128.exceedsTenToThirtyEight()",0,1,n/a,20,1,0,5,6
"org.apache.hadoop.hive.common.type.UnsignedInt128.fastSerializeForHiveDecimal(Decimal128FastBuffer,byte)",6,1,n/a,35,1,2,20,8
"org.apache.hadoop.hive.common.type.UnsignedInt128.fastSerializeIntPartForHiveDecimal(ByteBuffer,int,int,byte,boolean)",1,4,n/a,11,1,5,3,4
"org.apache.hadoop.hive.common.type.UnsignedInt128.fastUpdateFromInternalStorage(byte[])",5,1,n/a,99,5,1,77,30
"org.apache.hadoop.hive.common.type.UnsignedInt128.fastUpdateIntFromInternalStorage(byte[],byte,int,int)",1,4,n/a,49,1,4,24,9
"org.apache.hadoop.hive.common.type.UnsignedInt128.fitsInt32()",0,10,n/a,4,0,0,1,1
"org.apache.hadoop.hive.common.type.UnsignedInt128.getCount()",0,0,n/a,3,0,0,1,1
"org.apache.hadoop.hive.common.type.UnsignedInt128.getDigitsArray(int[])",3,1,n/a,52,3,1,34,8
"org.apache.hadoop.hive.common.type.UnsignedInt128.getIntsPerElement(int)",0,6,n/a,18,1,1,8,5
"org.apache.hadoop.hive.common.type.UnsignedInt128.getV()",0,0,n/a,3,0,0,1,1
"org.apache.hadoop.hive.common.type.UnsignedInt128.getV0()",0,17,n/a,4,0,0,1,1
"org.apache.hadoop.hive.common.type.UnsignedInt128.getV1()",0,14,n/a,4,0,0,1,1
"org.apache.hadoop.hive.common.type.UnsignedInt128.getV2()",0,12,n/a,4,0,0,1,1
"org.apache.hadoop.hive.common.type.UnsignedInt128.getV3()",0,22,n/a,4,0,0,1,1
"org.apache.hadoop.hive.common.type.UnsignedInt128.hashCode()",0,4,n/a,6,0,0,1,1
"org.apache.hadoop.hive.common.type.UnsignedInt128.incrementArray(int[])",1,5,n/a,12,2,1,9,4
"org.apache.hadoop.hive.common.type.UnsignedInt128.incrementConstructive()",2,0,n/a,11,0,0,3,1
"org.apache.hadoop.hive.common.type.UnsignedInt128.incrementDestructive()",2,5,n/a,8,0,0,2,1
"org.apache.hadoop.hive.common.type.UnsignedInt128.isOne()",0,1,n/a,4,0,0,1,2
"org.apache.hadoop.hive.common.type.UnsignedInt128.isZero()",0,36,n/a,4,0,0,1,1
"org.apache.hadoop.hive.common.type.UnsignedInt128.multiplyArrays4And4To4NoOverflow(int[],int[])",2,1,n/a,51,1,2,19,11
"org.apache.hadoop.hive.common.type.UnsignedInt128.multiplyArrays4And4To8(int[],int[])",0,3,n/a,50,0,2,20,1
"org.apache.hadoop.hive.common.type.UnsignedInt128.multiplyConstructive(UnsignedInt128)",2,0,n/a,13,0,1,3,1
"org.apache.hadoop.hive.common.type.UnsignedInt128.multiplyConstructive(int)",2,0,n/a,13,0,1,3,1
"org.apache.hadoop.hive.common.type.UnsignedInt128.multiplyConstructive256(UnsignedInt128)",1,1,n/a,10,0,1,1,1
"org.apache.hadoop.hive.common.type.UnsignedInt128.multiplyDestructive(UnsignedInt128)",5,3,n/a,15,1,1,5,3
"org.apache.hadoop.hive.common.type.UnsignedInt128.multiplyDestructive(int)",3,7,n/a,25,1,1,15,5
"org.apache.hadoop.hive.common.type.UnsignedInt128.multiplyDestructiveFitsInt32(UnsignedInt128,short,short)",10,3,n/a,23,1,3,14,8
"org.apache.hadoop.hive.common.type.UnsignedInt128.multiplyScaleDownTenDestructive(UnsignedInt128,short)",6,1,n/a,22,1,2,7,3
"org.apache.hadoop.hive.common.type.UnsignedInt128.multiplyShiftDestructive(UnsignedInt128,short)",6,1,n/a,19,1,2,6,3
"org.apache.hadoop.hive.common.type.UnsignedInt128.scaleDownFiveArray(int[],short)",3,2,n/a,22,2,2,8,3
"org.apache.hadoop.hive.common.type.UnsignedInt128.scaleDownFiveArrayRoundUp(int[],short)",2,1,n/a,6,1,2,3,2
"org.apache.hadoop.hive.common.type.UnsignedInt128.scaleDownFiveDestructive(short)",4,0,n/a,21,1,1,8,4
"org.apache.hadoop.hive.common.type.UnsignedInt128.scaleDownTenArray4RoundUp(int[],short)",2,4,n/a,15,0,2,2,1
"org.apache.hadoop.hive.common.type.UnsignedInt128.scaleDownTenArray8RoundUp(int[],short)",7,2,n/a,189,3,2,90,16
"org.apache.hadoop.hive.common.type.UnsignedInt128.scaleDownTenDestructive(short)",4,7,n/a,21,1,1,8,4
"org.apache.hadoop.hive.common.type.UnsignedInt128.scaleUpFiveDestructive(short)",4,2,n/a,25,1,1,10,5
"org.apache.hadoop.hive.common.type.UnsignedInt128.scaleUpTenArray(int[],short)",1,3,n/a,23,2,2,13,4
"org.apache.hadoop.hive.common.type.UnsignedInt128.scaleUpTenDestructive(short)",4,10,n/a,24,1,1,8,4
"org.apache.hadoop.hive.common.type.UnsignedInt128.serializeTo(IntBuffer,int)",2,1,n/a,12,0,2,1,1
"org.apache.hadoop.hive.common.type.UnsignedInt128.serializeTo(int[],int,int)",2,1,n/a,14,0,3,1,1
"org.apache.hadoop.hive.common.type.UnsignedInt128.serializeTo128(IntBuffer)",1,1,n/a,10,0,1,1,1
"org.apache.hadoop.hive.common.type.UnsignedInt128.serializeTo128(int[],int)",1,1,n/a,12,0,2,1,1
"org.apache.hadoop.hive.common.type.UnsignedInt128.serializeTo32(IntBuffer)",1,1,n/a,12,0,1,4,1
"org.apache.hadoop.hive.common.type.UnsignedInt128.serializeTo32(int[],int)",0,1,n/a,14,0,2,4,1
"org.apache.hadoop.hive.common.type.UnsignedInt128.serializeTo64(IntBuffer)",1,1,n/a,11,0,1,3,1
"org.apache.hadoop.hive.common.type.UnsignedInt128.serializeTo64(int[],int)",1,1,n/a,13,0,2,3,1
"org.apache.hadoop.hive.common.type.UnsignedInt128.serializeTo96(IntBuffer)",1,1,n/a,10,0,1,2,1
"org.apache.hadoop.hive.common.type.UnsignedInt128.serializeTo96(int[],int)",1,1,n/a,12,0,2,2,1
"org.apache.hadoop.hive.common.type.UnsignedInt128.setCount(byte)",0,0,n/a,6,0,1,1,1
"org.apache.hadoop.hive.common.type.UnsignedInt128.setV(int[])",1,0,n/a,10,0,1,5,1
"org.apache.hadoop.hive.common.type.UnsignedInt128.setV0(int)",1,0,n/a,10,0,1,2,1
"org.apache.hadoop.hive.common.type.UnsignedInt128.setV1(int)",1,0,n/a,10,0,1,2,1
"org.apache.hadoop.hive.common.type.UnsignedInt128.setV2(int)",1,0,n/a,10,0,1,2,1
"org.apache.hadoop.hive.common.type.UnsignedInt128.setV3(int)",1,0,n/a,10,0,1,2,1
"org.apache.hadoop.hive.common.type.UnsignedInt128.shiftLeftConstructive(int)",2,0,n/a,13,0,1,3,1
"org.apache.hadoop.hive.common.type.UnsignedInt128.shiftLeftDestructive(int)",1,3,n/a,12,0,1,2,1
"org.apache.hadoop.hive.common.type.UnsignedInt128.shiftLeftDestructive(int,int)",2,1,n/a,45,1,2,33,15
"org.apache.hadoop.hive.common.type.UnsignedInt128.shiftLeftDestructiveCheckOverflow(int)",3,3,n/a,14,1,1,3,2
"org.apache.hadoop.hive.common.type.UnsignedInt128.shiftRightArray(int,int[],int[],boolean)",4,2,n/a,67,4,4,40,17
"org.apache.hadoop.hive.common.type.UnsignedInt128.shiftRightConstructive(int,boolean)",2,1,n/a,15,0,2,3,1
"org.apache.hadoop.hive.common.type.UnsignedInt128.shiftRightDestructive(int,boolean)",1,3,n/a,13,0,2,2,1
"org.apache.hadoop.hive.common.type.UnsignedInt128.shiftRightDestructive(int,int,boolean)",4,1,n/a,61,1,3,43,21
"org.apache.hadoop.hive.common.type.UnsignedInt128.subtractConstructive(UnsignedInt128)",2,0,n/a,14,0,1,3,1
"org.apache.hadoop.hive.common.type.UnsignedInt128.subtractDestructive(UnsignedInt128)",1,1,n/a,12,0,1,1,1
"org.apache.hadoop.hive.common.type.UnsignedInt128.subtractDestructive(int[])",2,1,n/a,20,1,1,9,3
"org.apache.hadoop.hive.common.type.UnsignedInt128.throwIfExceedsTenToThirtyEight()",2,8,n/a,10,1,0,2,2
"org.apache.hadoop.hive.common.type.UnsignedInt128.toBigIntegerSlow()",10,2,n/a,16,0,0,8,1
"org.apache.hadoop.hive.common.type.UnsignedInt128.toFormalString()",4,4,n/a,37,3,0,25,7
"org.apache.hadoop.hive.common.type.UnsignedInt128.toString()",14,5,n/a,11,0,0,8,1
"org.apache.hadoop.hive.common.type.UnsignedInt128.update(BigInteger)",8,3,n/a,15,0,1,5,1
"org.apache.hadoop.hive.common.type.UnsignedInt128.update(IntBuffer,int)",6,1,n/a,27,1,2,15,6
"org.apache.hadoop.hive.common.type.UnsignedInt128.update(String)",3,1,n/a,9,0,1,1,1
"org.apache.hadoop.hive.common.type.UnsignedInt128.update(UnsignedInt128)",1,4,n/a,9,0,1,1,1
"org.apache.hadoop.hive.common.type.UnsignedInt128.update(char[],int,int)",8,3,n/a,49,2,3,27,10
"org.apache.hadoop.hive.common.type.UnsignedInt128.update(int,int,int,int)",1,16,n/a,19,0,4,5,1
"org.apache.hadoop.hive.common.type.UnsignedInt128.update(int[],int,int)",6,1,n/a,29,1,3,15,6
"org.apache.hadoop.hive.common.type.UnsignedInt128.update(long)",1,8,n/a,10,0,1,2,1
"org.apache.hadoop.hive.common.type.UnsignedInt128.update128(IntBuffer)",2,2,n/a,11,0,1,2,1
"org.apache.hadoop.hive.common.type.UnsignedInt128.update128(int[],int)",2,2,n/a,13,0,2,2,1
"org.apache.hadoop.hive.common.type.UnsignedInt128.update32(IntBuffer)",2,2,n/a,14,0,1,5,1
"org.apache.hadoop.hive.common.type.UnsignedInt128.update32(int[],int)",1,2,n/a,16,0,2,5,1
"org.apache.hadoop.hive.common.type.UnsignedInt128.update64(IntBuffer)",2,2,n/a,13,0,1,4,1
"org.apache.hadoop.hive.common.type.UnsignedInt128.update64(int[],int)",2,2,n/a,15,0,2,4,1
"org.apache.hadoop.hive.common.type.UnsignedInt128.update96(IntBuffer)",2,2,n/a,12,0,1,3,1
"org.apache.hadoop.hive.common.type.UnsignedInt128.update96(int[],int)",2,2,n/a,14,0,2,3,1
"org.apache.hadoop.hive.common.type.UnsignedInt128.updateCount()",0,28,n/a,14,1,0,9,5
"org.apache.hadoop.hive.common.type.UnsignedInt128.zeroClear()",0,9,n/a,8,0,0,5,1
"org.apache.hadoop.hive.conf.HiveConf.ConfVars.ConfVars(String,Object,String)",1,452,n/a,3,0,3,1,1
"org.apache.hadoop.hive.conf.HiveConf.ConfVars.ConfVars(String,Object,String,boolean)",1,5,n/a,3,0,4,1,1
"org.apache.hadoop.hive.conf.HiveConf.ConfVars.ConfVars(String,Object,Validator,String)",1,13,n/a,3,0,4,1,1
"org.apache.hadoop.hive.conf.HiveConf.ConfVars.ConfVars(String,Object,Validator,String,boolean,boolean)",4,4,n/a,52,1,6,47,8
"org.apache.hadoop.hive.conf.HiveConf.ConfVars.ConfVars(String,String,boolean,String)",1,1,n/a,3,0,4,1,1
"org.apache.hadoop.hive.conf.HiveConf.ConfVars.VarType.checkType(String)",n/a,1,5,n/a,n/a,1,n/a,n/a
"org.apache.hadoop.hive.conf.HiveConf.ConfVars.VarType.defaultValueString(ConfVars)",0,1,n/a,1,0,1,1,1
"org.apache.hadoop.hive.conf.HiveConf.ConfVars.VarType.isType(String)",1,1,n/a,4,1,1,4,2
"org.apache.hadoop.hive.conf.HiveConf.ConfVars.VarType.typeString()",2,1,n/a,1,0,0,1,1
"org.apache.hadoop.hive.conf.HiveConf.ConfVars.findHadoopBinary()",2,1,n/a,12,1,0,5,4
"org.apache.hadoop.hive.conf.HiveConf.ConfVars.getDefaultExpr()",0,1,n/a,3,0,0,1,1
"org.apache.hadoop.hive.conf.HiveConf.ConfVars.getDefaultValue()",1,1,n/a,3,0,0,1,1
"org.apache.hadoop.hive.conf.HiveConf.ConfVars.getDescription()",0,1,n/a,3,0,0,1,1
"org.apache.hadoop.hive.conf.HiveConf.ConfVars.isCaseSensitive()",0,0,n/a,3,0,0,1,1
"org.apache.hadoop.hive.conf.HiveConf.ConfVars.isExcluded()",0,1,n/a,3,0,0,1,1
"org.apache.hadoop.hive.conf.HiveConf.ConfVars.isType(String)",1,1,n/a,3,0,1,1,1
"org.apache.hadoop.hive.conf.HiveConf.ConfVars.toString()",0,5,n/a,4,0,0,1,1
"org.apache.hadoop.hive.conf.HiveConf.ConfVars.typeString()",1,1,n/a,3,0,0,1,1
"org.apache.hadoop.hive.conf.HiveConf.ConfVars.validate(String)",1,0,n/a,3,0,1,1,2
"org.apache.hadoop.hive.conf.HiveConf.HiveConf()",3,1,n/a,4,0,0,2,1
"org.apache.hadoop.hive.conf.HiveConf.HiveConf(Class<?>)",2,3,n/a,4,0,1,2,1
"org.apache.hadoop.hive.conf.HiveConf.HiveConf(Configuration,Class<?>)",2,0,n/a,4,0,2,2,1
"org.apache.hadoop.hive.conf.HiveConf.HiveConf(HiveConf)",3,0,n/a,10,0,1,5,1
"org.apache.hadoop.hive.conf.HiveConf.addToModifiableWhiteList(String)",1,0,n/a,12,1,1,3,2
"org.apache.hadoop.hive.conf.HiveConf.addToRestrictList(String)",5,0,n/a,16,1,1,7,4
"org.apache.hadoop.hive.conf.HiveConf.applyDefaultNonNullConfVars(Configuration)",3,1,n/a,13,2,1,5,3
"org.apache.hadoop.hive.conf.HiveConf.applySystemProperties()",5,1,n/a,10,1,0,3,2
"org.apache.hadoop.hive.conf.HiveConf.getAllProperties()",1,2,n/a,3,0,0,1,1
"org.apache.hadoop.hive.conf.HiveConf.getAuxJars()",0,0,n/a,6,0,0,1,1
"org.apache.hadoop.hive.conf.HiveConf.getBoolVar(ConfVars)",1,4,n/a,3,0,1,1,1
"org.apache.hadoop.hive.conf.HiveConf.getBoolVar(Configuration,ConfVars)",1,1,n/a,4,0,2,2,1
"org.apache.hadoop.hive.conf.HiveConf.getBoolVar(Configuration,ConfVars,boolean)",1,0,n/a,3,0,3,1,1
"org.apache.hadoop.hive.conf.HiveConf.getChangedProperties()",8,0,n/a,12,2,0,8,3
"org.apache.hadoop.hive.conf.HiveConf.getColumnInternalName(int)",0,0,n/a,3,0,1,1,1
"org.apache.hadoop.hive.conf.HiveConf.getConfSystemProperties()",7,1,n/a,15,3,0,6,4
"org.apache.hadoop.hive.conf.HiveConf.getConfVarInputStream()",7,1,n/a,29,2,0,9,3
"org.apache.hadoop.hive.conf.HiveConf.getConfVars(String)",1,2,n/a,3,0,1,1,1
"org.apache.hadoop.hive.conf.HiveConf.getFloatVar(ConfVars)",1,0,n/a,3,0,1,1,1
"org.apache.hadoop.hive.conf.HiveConf.getFloatVar(Configuration,ConfVars)",1,1,n/a,4,0,2,2,1
"org.apache.hadoop.hive.conf.HiveConf.getFloatVar(Configuration,ConfVars,float)",1,0,n/a,3,0,3,1,1
"org.apache.hadoop.hive.conf.HiveConf.getHiveDefaultLocation()",0,2,n/a,3,0,0,1,1
"org.apache.hadoop.hive.conf.HiveConf.getHiveServer2SiteLocation()",0,0,n/a,3,0,0,1,1
"org.apache.hadoop.hive.conf.HiveConf.getHiveSiteLocation()",0,2,n/a,3,0,0,1,1
"org.apache.hadoop.hive.conf.HiveConf.getIntVar(ConfVars)",1,0,n/a,3,0,1,1,1
"org.apache.hadoop.hive.conf.HiveConf.getIntVar(Configuration,ConfVars)",1,1,n/a,4,0,2,2,1
"org.apache.hadoop.hive.conf.HiveConf.getJar()",0,0,n/a,3,0,0,1,1
"org.apache.hadoop.hive.conf.HiveConf.getLongVar(ConfVars)",1,0,n/a,3,0,1,1,1
"org.apache.hadoop.hive.conf.HiveConf.getLongVar(Configuration,ConfVars)",1,1,n/a,4,0,2,2,1
"org.apache.hadoop.hive.conf.HiveConf.getLongVar(Configuration,ConfVars,long)",1,0,n/a,3,0,3,1,1
"org.apache.hadoop.hive.conf.HiveConf.getMetaConf(String)",1,0,n/a,3,0,1,1,1
"org.apache.hadoop.hive.conf.HiveConf.getMetastoreSiteLocation()",0,0,n/a,3,0,0,1,1
"org.apache.hadoop.hive.conf.HiveConf.getPositionFromInternalName(String)",5,0,n/a,9,1,1,5,2
"org.apache.hadoop.hive.conf.HiveConf.getProperties(Configuration)",7,1,n/a,9,1,1,6,2
"org.apache.hadoop.hive.conf.HiveConf.getUser()",4,0,n/a,13,1,0,4,2
"org.apache.hadoop.hive.conf.HiveConf.getVar(ConfVars)",1,3,n/a,3,0,1,1,1
"org.apache.hadoop.hive.conf.HiveConf.getVar(Configuration,ConfVars)",1,9,n/a,4,0,2,2,1
"org.apache.hadoop.hive.conf.HiveConf.getVar(Configuration,ConfVars,String)",1,0,n/a,3,0,3,1,1
"org.apache.hadoop.hive.conf.HiveConf.initialize(Class<?>)",42,3,n/a,79,4,1,43,22
"org.apache.hadoop.hive.conf.HiveConf.isLoadHiveServer2Config()",0,1,n/a,3,0,0,1,1
"org.apache.hadoop.hive.conf.HiveConf.isLoadMetastoreConfig()",0,1,n/a,3,0,0,1,1
"org.apache.hadoop.hive.conf.HiveConf.logVars(PrintStream)",4,0,n/a,5,1,1,2,3
"org.apache.hadoop.hive.conf.HiveConf.setAuxJars(String)",1,0,n/a,7,0,1,2,1
"org.apache.hadoop.hive.conf.HiveConf.setBoolVar(ConfVars,boolean)",1,2,n/a,3,0,2,1,1
"org.apache.hadoop.hive.conf.HiveConf.setBoolVar(Configuration,ConfVars,boolean)",1,1,n/a,4,0,3,2,1
"org.apache.hadoop.hive.conf.HiveConf.setFloatVar(ConfVars,float)",1,0,n/a,3,0,2,1,1
"org.apache.hadoop.hive.conf.HiveConf.setFloatVar(Configuration,ConfVars,float)",1,1,n/a,4,0,3,2,1
"org.apache.hadoop.hive.conf.HiveConf.setHiveSiteLocation(URL)",0,0,n/a,3,0,1,1,1
"org.apache.hadoop.hive.conf.HiveConf.setIntVar(ConfVars,int)",1,0,n/a,3,0,2,1,1
"org.apache.hadoop.hive.conf.HiveConf.setIntVar(Configuration,ConfVars,int)",1,1,n/a,4,0,3,2,1
"org.apache.hadoop.hive.conf.HiveConf.setIsModWhiteListEnabled(boolean)",0,0,n/a,9,0,1,1,1
"org.apache.hadoop.hive.conf.HiveConf.setLoadHiveServer2Config(boolean)",0,0,n/a,3,0,1,1,1
"org.apache.hadoop.hive.conf.HiveConf.setLoadMetastoreConfig(boolean)",0,1,n/a,3,0,1,1,1
"org.apache.hadoop.hive.conf.HiveConf.setLongVar(ConfVars,long)",1,0,n/a,3,0,2,1,1
"org.apache.hadoop.hive.conf.HiveConf.setLongVar(Configuration,ConfVars,long)",1,1,n/a,4,0,3,2,1
"org.apache.hadoop.hive.conf.HiveConf.setVar(ConfVars,String)",1,2,n/a,3,0,2,1,1
"org.apache.hadoop.hive.conf.HiveConf.setVar(Configuration,ConfVars,String)",1,2,n/a,4,0,3,2,1
"org.apache.hadoop.hive.conf.HiveConf.setupRestrictList()",7,2,n/a,15,2,0,7,3
"org.apache.hadoop.hive.conf.HiveConf.verifyAndSet(String,String)",5,0,n/a,13,2,2,6,4
"org.apache.hadoop.hive.conf.HiveConfUtil.isEmbeddedMetaStore(String)",2,1,n/a,10,0,1,1,2
"org.apache.hadoop.hive.conf.LoopingByteArrayInputStream.LoopingByteArrayInputStream(byte[])",0,1,n/a,3,0,1,1,1
"org.apache.hadoop.hive.conf.LoopingByteArrayInputStream.available()",2,0,n/a,4,0,0,1,1
"org.apache.hadoop.hive.conf.LoopingByteArrayInputStream.close()",4,1,n/a,6,0,0,2,1
"org.apache.hadoop.hive.conf.LoopingByteArrayInputStream.getByteArrayInputStream()",3,10,n/a,8,1,0,5,2
"org.apache.hadoop.hive.conf.LoopingByteArrayInputStream.mark(int)",2,0,n/a,4,0,1,1,1
"org.apache.hadoop.hive.conf.LoopingByteArrayInputStream.markSupported()",2,0,n/a,4,0,0,1,1
"org.apache.hadoop.hive.conf.LoopingByteArrayInputStream.read()",2,0,n/a,4,0,0,1,1
"org.apache.hadoop.hive.conf.LoopingByteArrayInputStream.read(byte[])",2,1,n/a,4,0,1,1,1
"org.apache.hadoop.hive.conf.LoopingByteArrayInputStream.read(byte[],int,int)",2,0,n/a,4,0,3,1,1
"org.apache.hadoop.hive.conf.LoopingByteArrayInputStream.reset()",2,0,n/a,4,0,0,1,1
"org.apache.hadoop.hive.conf.LoopingByteArrayInputStream.skip(long)",2,0,n/a,4,0,1,1,1
"org.apache.hadoop.hive.conf.SystemVariables.containsVar(String)",2,0,n/a,3,0,1,1,2
"org.apache.hadoop.hive.conf.SystemVariables.getSubstitute(Configuration,String)",13,1,n/a,17,2,2,10,8
"org.apache.hadoop.hive.conf.SystemVariables.substitute(Configuration,String)",2,0,n/a,3,0,2,1,2
"org.apache.hadoop.hive.conf.SystemVariables.substitute(Configuration,String,int)",18,2,n/a,34,3,3,26,6
"org.apache.hadoop.hive.conf.SystemVariables.substitute(String)",2,1,n/a,3,0,1,1,2
"org.apache.hadoop.hive.conf.Validator.PatternSet.PatternSet(String...)",2,2,n/a,5,1,1,2,2
"org.apache.hadoop.hive.conf.Validator.PatternSet.validate(String)",2,1,n/a,12,2,1,6,4
"org.apache.hadoop.hive.conf.Validator.RANGE_TYPE.inRange(String,Object,Object)",n/a,1,3,n/a,n/a,3,n/a,n/a
"org.apache.hadoop.hive.conf.Validator.RANGE_TYPE.valueOf(Object,Object)",1,1,n/a,13,1,2,10,7
"org.apache.hadoop.hive.conf.Validator.RangeValidator.RangeValidator(Object,Object)",1,1,n/a,5,0,2,3,1
"org.apache.hadoop.hive.conf.Validator.RangeValidator.validate(String)",3,1,n/a,14,2,1,7,4
"org.apache.hadoop.hive.conf.Validator.RatioValidator.validate(String)",2,1,n/a,12,2,1,6,4
"org.apache.hadoop.hive.conf.Validator.StringSet.StringSet(String...)",2,10,n/a,5,1,1,2,2
"org.apache.hadoop.hive.conf.Validator.StringSet.validate(String)",2,1,n/a,7,1,1,3,3
"org.apache.hadoop.hive.conf.Validator.validate(String)",n/a,1,4,n/a,n/a,1,n/a,n/a
"org.apache.hive.common.HiveCompat.CompatLevel.CompatLevel(String,int,int)",0,2,n/a,5,0,3,3,1
"org.apache.hive.common.HiveCompat.getCompatLevel(HiveConf)",2,0,n/a,8,0,1,1,1
"org.apache.hive.common.HiveCompat.getCompatLevel(String)",5,2,n/a,13,2,1,7,4
"org.apache.hive.common.HiveCompat.getLastCompatLevel()",1,1,n/a,4,0,0,2,1
"org.apache.hive.common.HiveVersionAnnotation.branch()",n/a,1,0,n/a,n/a,0,n/a,n/a
"org.apache.hive.common.HiveVersionAnnotation.date()",n/a,1,0,n/a,n/a,0,n/a,n/a
"org.apache.hive.common.HiveVersionAnnotation.revision()",n/a,1,0,n/a,n/a,0,n/a,n/a
"org.apache.hive.common.HiveVersionAnnotation.shortVersion()",n/a,1,0,n/a,n/a,0,n/a,n/a
"org.apache.hive.common.HiveVersionAnnotation.srcChecksum()",n/a,1,0,n/a,n/a,0,n/a,n/a
"org.apache.hive.common.HiveVersionAnnotation.url()",n/a,1,0,n/a,n/a,0,n/a,n/a
"org.apache.hive.common.HiveVersionAnnotation.user()",n/a,1,0,n/a,n/a,0,n/a,n/a
"org.apache.hive.common.HiveVersionAnnotation.version()",n/a,1,0,n/a,n/a,0,n/a,n/a
"org.apache.hive.common.util.AnnotationUtils.getAnnotation(Class<?>,Class<T>)",1,0,n/a,6,1,2,2,1
"org.apache.hive.common.util.AnnotationUtils.getAnnotation(Method,Class<T>)",1,0,n/a,6,1,2,2,1
"org.apache.hive.common.util.Decimal128FastBuffer.Decimal128FastBuffer()",9,0,n/a,18,0,0,16,1
"org.apache.hive.common.util.Decimal128FastBuffer.getByteBuffer(int)",0,1,n/a,3,0,1,1,1
"org.apache.hive.common.util.Decimal128FastBuffer.getBytes(int)",0,0,n/a,3,0,1,1,1
"org.apache.hive.common.util.HiveStringUtils.TraditionalBinaryPrefix.TraditionalBinaryPrefix(long)",2,6,n/a,4,0,1,2,1
"org.apache.hive.common.util.HiveStringUtils.TraditionalBinaryPrefix.string2long(String)",10,0,n/a,34,2,1,13,5
"org.apache.hive.common.util.HiveStringUtils.TraditionalBinaryPrefix.valueOf(char)",3,1,n/a,12,2,1,5,3
"org.apache.hive.common.util.HiveStringUtils.arrayToString(String[])",5,0,n/a,16,1,1,10,3
"org.apache.hive.common.util.HiveStringUtils.byteDesc(long)",1,0,n/a,24,1,1,17,5
"org.apache.hive.common.util.HiveStringUtils.byteToHexString(byte[])",1,0,n/a,4,0,1,1,1
"org.apache.hive.common.util.HiveStringUtils.byteToHexString(byte[],int,int)",5,1,n/a,18,1,3,8,3
"org.apache.hive.common.util.HiveStringUtils.camelize(String)",6,0,n/a,14,1,1,5,2
"org.apache.hive.common.util.HiveStringUtils.escapeHTML(String)",10,0,n/a,34,3,1,30,10
"org.apache.hive.common.util.HiveStringUtils.escapeString(String)",1,0,n/a,8,0,1,1,1
"org.apache.hive.common.util.HiveStringUtils.escapeString(String,char,char)",1,1,n/a,13,0,3,1,1
"org.apache.hive.common.util.HiveStringUtils.escapeString(String,char,char[])",7,1,n/a,19,2,3,11,5
"org.apache.hive.common.util.HiveStringUtils.findNext(String,char,char,int,StringBuilder)",3,1,n/a,26,2,5,10,5
"org.apache.hive.common.util.HiveStringUtils.formatPercent(double,int)",7,0,n/a,15,0,2,7,1
"org.apache.hive.common.util.HiveStringUtils.formatTime(long)",8,1,n/a,27,1,1,15,3
"org.apache.hive.common.util.HiveStringUtils.formatTimeDiff(long,long)",1,1,n/a,13,0,2,2,1
"org.apache.hive.common.util.HiveStringUtils.getFormattedTimeWithDiff(DateFormat,long,long)",7,0,n/a,21,2,3,6,3
"org.apache.hive.common.util.HiveStringUtils.getHostname()",1,1,n/a,8,1,0,3,2
"org.apache.hive.common.util.HiveStringUtils.getStringCollection(String)",6,1,n/a,17,1,1,8,3
"org.apache.hive.common.util.HiveStringUtils.getStrings(String)",4,0,n/a,12,1,1,4,2
"org.apache.hive.common.util.HiveStringUtils.getTextUtfLength(Text)",3,0,n/a,10,2,1,8,3
"org.apache.hive.common.util.HiveStringUtils.getTrimmedStringCollection(String)",3,0,n/a,9,0,1,1,1
"org.apache.hive.common.util.HiveStringUtils.getTrimmedStrings(String)",4,1,n/a,11,1,1,3,3
"org.apache.hive.common.util.HiveStringUtils.hasChar(char[],char)",0,3,n/a,9,2,2,4,3
"org.apache.hive.common.util.HiveStringUtils.hexStringToByte(String)",3,0,n/a,14,1,1,6,2
"org.apache.hive.common.util.HiveStringUtils.humanReadableInt(long)",3,0,n/a,26,1,1,14,4
"org.apache.hive.common.util.HiveStringUtils.isUtfStartByte(byte)",0,1,n/a,7,0,1,1,1
"org.apache.hive.common.util.HiveStringUtils.join(CharSequence,Iterable<?>)",11,0,n/a,18,1,2,8,3
"org.apache.hive.common.util.HiveStringUtils.limitDecimalTo2(double)",1,1,n/a,3,0,1,1,1
"org.apache.hive.common.util.HiveStringUtils.simpleHostname(String)",2,0,n/a,12,1,1,4,2
"org.apache.hive.common.util.HiveStringUtils.split(String)",1,0,n/a,8,0,1,1,1
"org.apache.hive.common.util.HiveStringUtils.split(String,char)",13,0,n/a,28,1,2,13,5
"org.apache.hive.common.util.HiveStringUtils.split(String,char,char)",14,2,n/a,28,1,3,14,5
"org.apache.hive.common.util.HiveStringUtils.startupShutdownMessage(Class<?>,String[],Log)",15,0,n/a,5,2,3,5,1
"org.apache.hive.common.util.HiveStringUtils.stringToPath(String[])",1,0,n/a,14,1,1,8,3
"org.apache.hive.common.util.HiveStringUtils.stringToURI(String[])",2,0,n/a,23,2,1,10,4
"org.apache.hive.common.util.HiveStringUtils.stringifyException(Throwable)",5,0,n/a,12,0,1,5,1
"org.apache.hive.common.util.HiveStringUtils.toStartupShutdownString(String,String[])",5,2,n/a,15,1,2,6,2
"org.apache.hive.common.util.HiveStringUtils.unEscapeString(String)",1,0,n/a,8,0,1,1,1
"org.apache.hive.common.util.HiveStringUtils.unEscapeString(String,char,char)",1,1,n/a,13,0,3,1,1
"org.apache.hive.common.util.HiveStringUtils.unEscapeString(String,char,char[])",12,1,n/a,38,3,3,21,9
"org.apache.hive.common.util.HiveStringUtils.uriToString(URI[])",6,0,n/a,15,1,1,9,3
"org.apache.hive.common.util.HiveTestUtils.getFileFromClasspath(String)",3,0,n/a,7,1,1,4,2
"org.apache.hive.common.util.HiveVersionInfo.getBranch()",1,0,n/a,7,0,0,1,2
"org.apache.hive.common.util.HiveVersionInfo.getBuildVersion()",4,0,n/a,10,0,0,1,1
"org.apache.hive.common.util.HiveVersionInfo.getDate()",1,2,n/a,7,0,0,1,2
"org.apache.hive.common.util.HiveVersionInfo.getPackage()",0,0,n/a,7,0,0,1,1
"org.apache.hive.common.util.HiveVersionInfo.getRevision()",1,3,n/a,7,0,0,1,2
"org.apache.hive.common.util.HiveVersionInfo.getShortVersion()",1,0,n/a,7,0,0,1,2
"org.apache.hive.common.util.HiveVersionInfo.getSrcChecksum()",1,2,n/a,7,0,0,1,2
"org.apache.hive.common.util.HiveVersionInfo.getUrl()",1,2,n/a,6,0,0,1,2
"org.apache.hive.common.util.HiveVersionInfo.getUser()",1,3,n/a,7,0,0,1,2
"org.apache.hive.common.util.HiveVersionInfo.getVersion()",1,3,n/a,7,0,0,1,2
"org.apache.hive.common.util.HiveVersionInfo.main(String[])",11,0,n/a,7,0,1,5,1
"org.apache.hive.common.util.ShutdownHookManager.HookEntry.HookEntry(Runnable,int)",0,3,n/a,4,0,2,2,1
"org.apache.hive.common.util.ShutdownHookManager.HookEntry.equals(Object)",0,2,n/a,10,2,1,5,3
"org.apache.hive.common.util.ShutdownHookManager.HookEntry.hashCode()",1,1,n/a,4,0,0,1,1
"org.apache.hive.common.util.ShutdownHookManager.ShutdownHookManager()",0,1,n/a,3,0,0,0,1
"org.apache.hive.common.util.ShutdownHookManager.addShutdownHook(Runnable,int)",1,1,n/a,11,0,2,1,1
"org.apache.hive.common.util.ShutdownHookManager.addShutdownHookInternal(Runnable,int)",5,1,n/a,9,1,2,5,3
"org.apache.hive.common.util.ShutdownHookManager.getShutdownHooksInOrder()",1,1,n/a,9,0,0,1,1
"org.apache.hive.common.util.ShutdownHookManager.getShutdownHooksInOrderInternal()",5,1,n/a,5,2,0,9,2
"org.apache.hive.common.util.ShutdownHookManager.hasShutdownHook(Runnable)",1,0,n/a,9,0,1,1,1
"org.apache.hive.common.util.ShutdownHookManager.hasShutdownHookInternal(Runnable)",2,1,n/a,3,0,1,1,1
"org.apache.hive.common.util.ShutdownHookManager.isShutdownInProgress()",1,0,n/a,8,0,0,1,1
"org.apache.hive.common.util.ShutdownHookManager.isShutdownInProgressInternal()",1,1,n/a,3,0,0,1,1
"org.apache.hive.common.util.ShutdownHookManager.removeShutdownHook(Runnable)",1,0,n/a,10,0,1,1,1
"org.apache.hive.common.util.ShutdownHookManager.removeShutdownHookInternal(Runnable)",4,1,n/a,6,1,1,3,2
"org.apache.hive.common.util.StreamPrinter.StreamPrinter(InputStream,String,PrintStream)",0,2,n/a,5,0,3,3,1
"org.apache.hive.common.util.StreamPrinter.run()",9,1,n/a,24,3,0,14,5

Class,CBO,CSA,CSO,CSOA,Dcy*,DIT,Inner,LCOM,LOC,NCLOC,NOC,NOIC,NOOC,OCavg,Query,RFC,WMC
"org.apache.hadoop.hive.ant.GenHiveTemplate",2,1,9,10,14,1,0,1,116,111,0,0,0,"2,00",4,44,18
"org.apache.hadoop.hive.common.CompressionUtils",1,0,13,13,1,1,0,1,39,27,0,11,0,"2,00",0,7,2
"org.apache.hadoop.hive.common.FileUtils",4,3,35,38,15,1,0,9,572,350,0,11,0,"2,88",19,49,72
"org.apache.hadoop.hive.common.FileUtils.AcceptAllPathFilter",1,0,13,13,0,1,0,1,9,6,0,11,0,"1,00",1,1,1
"org.apache.hadoop.hive.common.HiveInterruptCallback",n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,1,n/a
"org.apache.hadoop.hive.common.HiveInterruptUtils",1,1,16,17,1,1,0,2,42,33,0,11,0,"1,50",2,13,6
"org.apache.hadoop.hive.common.HiveStatsUtils",1,0,13,13,16,1,0,1,44,21,0,11,0,"3,00",1,7,3
"org.apache.hadoop.hive.common.JavaUtils",0,2,17,19,0,1,0,2,94,74,0,11,0,"2,80",2,23,14
"org.apache.hadoop.hive.common.LogUtils",3,3,17,20,15,1,0,1,105,82,0,11,0,"3,20",4,21,16
"org.apache.hadoop.hive.common.LogUtils.LogInitializationException",1,5,44,49,0,3,1,0,6,6,0,26,0,"1,00",0,2,1
"org.apache.hadoop.hive.common.ObjectPair",0,2,22,24,0,1,0,3,48,44,0,9,2,"1,30",6,11,13
"org.apache.hadoop.hive.common.ServerUtils",2,1,13,14,14,1,0,1,23,17,0,11,0,"2,00",0,2,2
"org.apache.hadoop.hive.common.StatsSetupConst",0,14,13,27,0,1,0,1,57,21,0,11,0,"2,00",1,3,2
"org.apache.hadoop.hive.common.StatsSetupConst.StatDB",2,7,27,34,14,n/a,2,2,49,49,n/a,20,0,"1,10",2,2,11
"org.apache.hadoop.hive.common.ValidTxnList",n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,6,n/a
"org.apache.hadoop.hive.common.ValidTxnList.RangeResponse",2,5,25,30,0,n/a,2,0,5,1,n/a,20,0,n/a,0,0,0
"org.apache.hadoop.hive.common.ValidTxnListImpl",3,2,28,30,3,1,1,1,90,87,0,10,1,"2,20",6,20,22
"org.apache.hadoop.hive.common.classification.InterfaceAudience",0,0,13,13,0,1,0,0,6,3,0,11,0,"1,00",0,1,1
"org.apache.hadoop.hive.common.classification.InterfaceAudience.LimitedPrivate",n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,1,n/a
"org.apache.hadoop.hive.common.classification.InterfaceAudience.Private",n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,0,n/a
"org.apache.hadoop.hive.common.classification.InterfaceAudience.Public",n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,0,n/a
"org.apache.hadoop.hive.common.classification.InterfaceStability",0,0,12,12,0,1,0,0,6,2,0,11,0,n/a,0,0,0
"org.apache.hadoop.hive.common.classification.InterfaceStability.Evolving",n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,0,n/a
"org.apache.hadoop.hive.common.classification.InterfaceStability.Stable",n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,0,n/a
"org.apache.hadoop.hive.common.classification.InterfaceStability.Unstable",n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,0,n/a
"org.apache.hadoop.hive.common.cli.CommonCliOptions",0,4,17,21,0,1,0,1,96,54,0,11,0,"2,00",2,10,10
"org.apache.hadoop.hive.common.cli.HiveFileProcessor",1,0,18,18,1,1,1,1,71,45,0,11,0,"3,00",5,11,9
"org.apache.hadoop.hive.common.cli.IHiveFileProcessor",n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,1,n/a
"org.apache.hadoop.hive.common.cli.ShellCmdExecutor",1,3,14,17,1,1,0,1,25,25,0,11,0,"1,00",1,11,2
"org.apache.hadoop.hive.common.io.CachingPrintStream",0,8,82,90,0,4,4,1,24,23,0,49,2,"1,00",1,11,5
"org.apache.hadoop.hive.common.io.DigestPrintStream",1,10,90,100,1,5,4,1,16,16,0,60,0,"1,00",0,10,3
"org.apache.hadoop.hive.common.io.FetchConverter",3,9,87,96,0,4,4,1,42,42,2,49,2,"1,38",1,13,11
"org.apache.hadoop.hive.common.io.NonSyncByteArrayInputStream",1,4,44,48,1,3,2,1,78,62,0,20,4,"1,80",6,15,18
"org.apache.hadoop.hive.common.io.NonSyncByteArrayOutputStream",1,2,45,47,1,3,3,1,74,58,0,20,4,"1,40",3,16,14
"org.apache.hadoop.hive.common.io.SortAndDigestPrintStream",2,11,92,103,2,6,4,1,17,17,0,61,1,"1,50",0,9,3
"org.apache.hadoop.hive.common.io.SortPrintStream",2,11,90,101,1,5,4,1,24,24,1,60,0,"1,25",0,5,5
"org.apache.hadoop.hive.common.metrics.Metrics",3,4,22,26,3,1,0,1,126,106,0,11,0,"2,27",5,30,25
"org.apache.hadoop.hive.common.metrics.Metrics.MetricsScope",1,6,18,24,3,1,0,1,74,50,0,11,0,"1,67",2,14,10
"org.apache.hadoop.hive.common.metrics.MetricsMBean",n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,4,n/a
"org.apache.hadoop.hive.common.metrics.MetricsMBeanImpl",2,6,33,39,1,1,2,1,128,123,0,11,0,"1,73",7,36,19
"org.apache.hadoop.hive.common.type.Decimal128",5,11,103,114,5,2,2,2,1.824,835,0,10,3,"2,29",44,173,190
"org.apache.hadoop.hive.common.type.HiveBaseChar",2,1,21,22,0,1,0,1,57,49,2,9,2,"1,56",6,14,14
"org.apache.hadoop.hive.common.type.HiveChar",1,2,32,34,1,2,1,2,57,49,0,10,5,"1,25",7,20,15
"org.apache.hadoop.hive.common.type.HiveDecimal",1,12,50,62,0,1,1,3,197,177,0,8,3,"1,41",36,71,52
"org.apache.hadoop.hive.common.type.HiveVarchar",1,2,27,29,1,2,1,3,40,30,0,17,0,"1,29",2,12,9
"org.apache.hadoop.hive.common.type.SignedInt128",2,5,95,100,4,2,2,2,967,444,0,10,3,"1,65",18,116,124
"org.apache.hadoop.hive.common.type.SqlMathUtil",4,23,30,53,3,1,0,5,522,315,0,11,0,"3,61",14,27,65
"org.apache.hadoop.hive.common.type.UnsignedInt128",5,8,137,145,3,1,2,1,2.436,1.506,0,7,4,"2,82",50,159,350
"org.apache.hadoop.hive.conf.HiveConf",9,19,59,78,13,1,0,6,537,446,0,0,0,"1,69",32,105,100
"org.apache.hadoop.hive.conf.HiveConf.ConfVars",13,499,40,539,13,n/a,2,7,1.544,1.439,n/a,18,1,"1,67",10,27,25
"org.apache.hadoop.hive.conf.HiveConf.ConfVars.VarType",1,7,29,36,13,n/a,2,3,31,31,n/a,20,0,"1,00",3,6,9
"org.apache.hadoop.hive.conf.HiveConfUtil",1,0,13,13,0,1,0,1,16,6,0,11,0,"2,00",1,3,2
"org.apache.hadoop.hive.conf.LoopingByteArrayInputStream",1,2,35,37,0,2,2,1,73,58,0,11,8,"1,08",7,24,13
"org.apache.hadoop.hive.conf.SystemVariables",1,8,17,25,0,1,0,1,70,70,0,11,0,"3,00",5,24,15
"org.apache.hadoop.hive.conf.Validator",n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,1,n/a
"org.apache.hadoop.hive.conf.Validator.PatternSet",2,1,15,16,1,1,1,1,20,20,0,11,0,"3,00",1,7,6
"org.apache.hadoop.hive.conf.Validator.RANGE_TYPE",1,5,27,32,0,n/a,2,2,37,37,n/a,20,0,"1,75",2,3,7
"org.apache.hadoop.hive.conf.Validator.RangeValidator",3,3,15,18,2,1,1,1,23,23,0,11,0,"2,00",1,6,4
"org.apache.hadoop.hive.conf.Validator.RatioValidator",1,0,14,14,1,1,1,1,14,14,0,11,0,"2,00",1,3,2
"org.apache.hadoop.hive.conf.Validator.StringSet",2,1,15,16,1,1,1,1,15,15,0,11,0,"2,00",1,6,4
"org.apache.hive.common.HiveCompat",4,3,15,18,13,1,0,2,30,25,0,11,0,"2,00",3,7,6
"org.apache.hive.common.HiveCompat.CompatLevel",1,7,26,33,0,n/a,2,0,16,12,n/a,20,0,"1,00",0,1,1
"org.apache.hive.common.HiveVersionAnnotation",n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,n/a,8,n/a
"org.apache.hive.common.util.AnnotationUtils",0,0,14,14,0,1,0,2,14,12,0,11,0,"1,00",2,4,2
"org.apache.hive.common.util.Decimal128FastBuffer",2,2,15,17,0,1,0,2,38,28,0,11,0,"1,00",2,5,3
"org.apache.hive.common.util.HiveStringUtils",3,7,51,58,5,1,0,15,667,439,0,11,0,"2,58",38,110,103
"org.apache.hive.common.util.HiveStringUtils.TraditionalBinaryPrefix",0,10,28,38,0,n/a,2,1,65,45,n/a,20,0,"2,33",2,13,7
"org.apache.hive.common.util.HiveTestUtils",0,0,13,13,0,1,0,1,11,11,0,11,0,"2,00",1,4,2
"org.apache.hive.common.util.HiveVersionInfo",2,3,23,26,1,1,0,2,94,51,0,11,0,"1,73",10,22,19
"org.apache.hive.common.util.ShutdownHookManager",2,4,23,27,1,1,0,1,125,80,0,11,0,"1,38",8,28,18
"org.apache.hive.common.util.ShutdownHookManager.HookEntry",1,2,15,17,0,1,0,0,25,22,0,9,2,"1,67",2,4,5
"org.apache.hive.common.util.StreamPrinter",1,27,68,95,0,2,1,1,38,34,0,42,1,"2,50",0,8,5

Package,C(rec),LOC(rec),METH(rec)
"",80,13.051,754
"org",80,13.051,754
"org.apache",80,13.051,754
"org.apache.hadoop",65,11.676,664
"org.apache.hadoop.hive",65,11.676,664
"org.apache.hadoop.hive.ant",1,150,9
"org.apache.hadoop.hive.common",51,9.007,540
"org.apache.hadoop.hive.common.classification",8,81,2
"org.apache.hadoop.hive.common.cli",4,291,13
"org.apache.hadoop.hive.common.io",8,424,44
"org.apache.hadoop.hive.common.metrics",5,431,32
"org.apache.hadoop.hive.common.type",8,6.255,365
"org.apache.hadoop.hive.conf",13,2.519,115
"org.apache.hive",15,1.375,90
"org.apache.hive.common",15,1.375,90
"org.apache.hive.common.util",12,1.237,78

Project,C,L(J),LOCp,METH
"project",80,13.051,13.051,750

